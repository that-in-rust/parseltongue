//! Main orchestrator for Tool 2: cozo-code-simulation-sorcerer
//!
//! Coordinates all components to provide complete code change simulation capabilities

use crate::{
    confidence_scorer::ConfidenceScorer, debugging_info::DebuggingInfoGenerator,
    graph_analyzer::GraphAnalysisResult, reasoning_engine::ReasoningResult, ChangeRequest,
    ConfidenceScore, ConfidenceThreshold, DebuggingInfo, GraphAnalyzer, ReasoningEngine,
    SimulationPlan,
};
use parseltongue_01::{
    streaming::CodeGraph,
    types::{CoreError, CoreResult},
};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use uuid::Uuid;

/// Main orchestrator for code change simulation
#[derive(Debug, Clone)]
pub struct CozoCodeSimulationSorcerer {
    /// Mock reasoning engine (for now, could be extended for other engines)
    reasoning_engine: crate::reasoning_engine::MockReasoningEngine,

    /// Graph analyzer for ISG traversal
    graph_analyzer: GraphAnalyzer,

    /// Confidence scorer for validation
    confidence_scorer: ConfidenceScorer,

    /// Debugging info generator
    debugging_generator: DebuggingInfoGenerator,

    /// Configuration for the sorcerer
    config: SorcererConfig,

    /// Whether this sorcerer was created with custom dependencies
    is_custom: bool,
}

/// Configuration for the sorcerer
#[derive(Debug, Clone)]
pub struct SorcererConfig {
    /// Default confidence threshold
    pub default_confidence_threshold: f64,

    /// Whether to enforce confidence thresholds strictly
    pub strict_confidence_enforcement: bool,

    /// Maximum execution time for simulations (seconds)
    pub max_execution_time_seconds: u64,

    /// Whether to generate debugging artifacts automatically
    pub auto_generate_debugging: bool,

    /// Custom reasoning engine configuration
    pub reasoning_engine_config: Option<HashMap<String, String>>,
}

/// Result from a complete simulation workflow
#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub struct SimulationResult {
    /// Unique identifier for this simulation
    pub id: Uuid,

    /// Change request that was simulated
    pub change_request: ChangeRequest,

    /// Generated simulation plan
    pub simulation_plan: SimulationPlan,

    /// Reasoning result from LLM analysis
    pub reasoning_result: ReasoningResult,

    /// Graph analysis result
    pub graph_analysis: GraphAnalysisResult,

    /// Confidence score for the simulation
    pub confidence_score: ConfidenceScore,

    /// Debugging information
    pub debugging_info: Option<DebuggingInfo>,

    /// Execution status
    pub status: SimulationStatus,

    /// Metadata about the simulation
    pub metadata: SimulationMetadata,
}

/// Status of simulation execution
#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub enum SimulationStatus {
    /// Simulation is pending
    Pending,
    /// Simulation is in progress
    InProgress,
    /// Simulation completed successfully
    Completed,
    /// Simulation failed
    Failed,
    /// Simulation was cancelled
    Cancelled,
}

/// Metadata about simulation execution
#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub struct SimulationMetadata {
    /// When simulation started
    pub started_at: chrono::DateTime<chrono::Utc>,

    /// When simulation completed (if applicable)
    pub completed_at: Option<chrono::DateTime<chrono::Utc>>,

    /// Total execution time in milliseconds
    pub execution_time_ms: Option<u64>,

    /// Memory usage during simulation (bytes)
    pub memory_usage_bytes: Option<u64>,

    /// Number of steps executed
    pub steps_executed: u32,

    /// Number of steps that failed
    pub steps_failed: u32,

    /// Warnings generated during simulation
    pub warnings: Vec<String>,
}

/// Result from executing a simulation plan
#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub struct SimulationExecutionResult {
    /// Unique identifier
    pub id: Uuid,

    /// Simulation plan that was executed
    pub plan: SimulationPlan,

    /// Execution results for each step
    pub step_results: Vec<StepExecutionResult>,

    /// Overall success status
    pub success: bool,

    /// Total execution time
    pub execution_time_ms: u64,

    /// Any errors that occurred
    pub errors: Vec<String>,

    /// Warnings generated
    pub warnings: Vec<String>,
}

/// Result from executing a single simulation step
#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub struct StepExecutionResult {
    /// Step that was executed
    pub step_id: Uuid,

    /// Step phase
    pub phase: String,

    /// Whether the step succeeded
    pub success: bool,

    /// Execution time in milliseconds
    pub execution_time_ms: u64,

    /// Output generated by the step
    pub output: Vec<String>,

    /// Errors that occurred
    pub errors: Vec<String>,

    /// Validation results
    pub validation_results: Vec<String>,
}

impl CozoCodeSimulationSorcerer {
    /// Create a new sorcerer with default configuration
    pub fn new() -> Self {
        let config = SorcererConfig {
            default_confidence_threshold: 0.8,
            strict_confidence_enforcement: true,
            max_execution_time_seconds: 300, // 5 minutes
            auto_generate_debugging: true,
            reasoning_engine_config: None,
        };

        Self::with_config(config)
    }

    /// Create a sorcerer with custom configuration
    pub fn with_config(config: SorcererConfig) -> Self {
        // Use mock reasoning engine by default
        let reasoning_engine = crate::reasoning_engine::MockReasoningEngine::default();

        Self {
            reasoning_engine,
            graph_analyzer: GraphAnalyzer::new(),
            confidence_scorer: ConfidenceScorer::new(),
            debugging_generator: DebuggingInfoGenerator::new(),
            config,
            is_custom: false,
        }
    }

    /// Create a sorcerer with custom dependencies (for dependency injection)
    pub fn with_dependencies(
        reasoning_engine: crate::reasoning_engine::MockReasoningEngine,
        graph_analyzer: GraphAnalyzer,
    ) -> Self {
        let config = SorcererConfig {
            default_confidence_threshold: 0.8,
            strict_confidence_enforcement: true,
            max_execution_time_seconds: 300,
            auto_generate_debugging: true,
            reasoning_engine_config: None,
        };

        Self {
            reasoning_engine,
            graph_analyzer,
            confidence_scorer: ConfidenceScorer::new(),
            debugging_generator: DebuggingInfoGenerator::new(),
            config,
            is_custom: true,
        }
    }

    /// Simulate a complete change request
    pub async fn simulate_change(
        &mut self,
        change_request: &ChangeRequest,
        code_graph: &CodeGraph,
    ) -> CoreResult<SimulationResult> {
        let start_time = std::time::Instant::now();
        let simulation_id = Uuid::new_v4();

        // Validate the change request first
        let validation_result = change_request.validate()?;
        if !validation_result.is_valid {
            return Err(CoreError::InvalidKey(format!(
                "Change request validation failed: {:?}",
                validation_result.errors
            )));
        }

        // Phase 1: Reasoning about the change
        let reasoning_result = self
            .reasoning_engine
            .reason_about_change(change_request, code_graph)
            .await
            .map_err(|e| CoreError::ResourceNotFound(format!("Reasoning failed: {:?}", e)))?;

        // Phase 2: Generate simulation plan
        let simulation_plan = self
            .reasoning_engine
            .generate_simulation_plan(change_request, code_graph, &reasoning_result)
            .await
            .map_err(|e| CoreError::ResourceNotFound(format!("Plan generation failed: {:?}", e)))?;

        // Validate the simulation plan
        let plan_errors = simulation_plan.validate()?;
        if !plan_errors.is_empty() {
            return Err(CoreError::InvalidKey(format!(
                "Simulation plan validation failed: {:?}",
                plan_errors
            )));
        }

        // Phase 3: Graph analysis
        let graph_analysis = self
            .graph_analyzer
            .analyze_change_impact(change_request, code_graph)
            .await
            .map_err(|e| CoreError::ResourceNotFound(format!("Graph analysis failed: {:?}", e)))?;

        // Phase 4: Calculate confidence score
        let confidence_score = self
            .confidence_scorer
            .calculate_confidence(change_request, code_graph, &simulation_plan)
            .await
            .map_err(|e| {
                CoreError::ResourceNotFound(format!("Confidence scoring failed: {:?}", e))
            })?;

        // Phase 5: Check confidence threshold
        let threshold = ConfidenceThreshold::new(self.config.default_confidence_threshold);
        if !threshold.meets_threshold(&confidence_score) {
            let errors = threshold.validation_errors(&confidence_score);
            return Err(CoreError::InvalidKey(format!(
                "Confidence threshold not met: {:?}",
                errors
            )));
        }

        // Phase 6: Generate debugging info (if enabled)
        let debugging_info = if self.config.auto_generate_debugging {
            Some(
                self.debugging_generator
                    .generate_debugging_info(
                        change_request,
                        &simulation_plan,
                        Some(&confidence_score),
                    )
                    .await
                    .map_err(|e| {
                        CoreError::ResourceNotFound(format!("Debugging generation failed: {:?}", e))
                    })?,
            )
        } else {
            None
        };

        let execution_time = start_time.elapsed().as_millis() as u64;

        Ok(SimulationResult {
            id: simulation_id,
            change_request: change_request.clone(),
            simulation_plan,
            reasoning_result,
            graph_analysis,
            confidence_score,
            debugging_info,
            status: SimulationStatus::Completed,
            metadata: SimulationMetadata {
                started_at: chrono::Utc::now(),
                completed_at: Some(chrono::Utc::now()),
                execution_time_ms: Some(execution_time),
                memory_usage_bytes: None, // Could be implemented with memory profiling
                steps_executed: 0,        // Updated during execution
                steps_failed: 0,
                warnings: vec![],
            },
        })
    }

    /// Generate a simulation plan for a change request
    pub async fn generate_simulation_plan(
        &mut self,
        change_request: &ChangeRequest,
        code_graph: &CodeGraph,
    ) -> CoreResult<SimulationPlan> {
        // Validate change request
        let validation_result = change_request.validate()?;
        if !validation_result.is_valid {
            return Err(CoreError::InvalidKey(format!(
                "Change request validation failed: {:?}",
                validation_result.errors
            )));
        }

        // Get reasoning about the change
        let reasoning_result = self
            .reasoning_engine
            .reason_about_change(change_request, code_graph)
            .await
            .map_err(|e| CoreError::ResourceNotFound(format!("Reasoning failed: {:?}", e)))?;

        // Generate simulation plan based on reasoning
        let simulation_plan = self
            .reasoning_engine
            .generate_simulation_plan(change_request, code_graph, &reasoning_result)
            .await
            .map_err(|e| CoreError::ResourceNotFound(format!("Plan generation failed: {:?}", e)))?;

        // Validate the generated plan
        let plan_errors = simulation_plan.validate()?;
        if !plan_errors.is_empty() {
            return Err(CoreError::InvalidKey(format!(
                "Simulation plan validation failed: {:?}",
                plan_errors
            )));
        }

        Ok(simulation_plan)
    }

    /// Execute a simulation plan
    pub async fn execute_simulation_plan(
        &self,
        plan: &SimulationPlan,
    ) -> CoreResult<SimulationExecutionResult> {
        let start_time = std::time::Instant::now();
        let execution_id = Uuid::new_v4();

        let mut step_results = Vec::new();
        let mut errors = Vec::new();
        let mut warnings = Vec::new();
        let mut success = true;

        // Execute each step in order
        for step in plan.steps() {
            let step_start = std::time::Instant::now();
            let step_success = true;
            let step_errors = Vec::new();
            let mut step_output = Vec::new();
            let mut validation_results = Vec::new();

            // Simulate some processing time (1-10ms based on step type)
            let processing_delay = std::time::Duration::from_millis(match step.step_type {
                crate::simulation_plan::SimulationStepType::Analysis => 2,
                crate::simulation_plan::SimulationStepType::ImpactAssessment => 3,
                crate::simulation_plan::SimulationStepType::ChangeApplication => 5,
                crate::simulation_plan::SimulationStepType::Validation => 4,
                crate::simulation_plan::SimulationStepType::Custom(_) => 2,
            });
            tokio::time::sleep(processing_delay).await;

            // Mock execution based on step type
            match step.step_type {
                crate::simulation_plan::SimulationStepType::Analysis => {
                    step_output.push(format!("Analyzed {} for {}", step.title, step.description));
                    validation_results.push("Analysis complete".to_string());
                }
                crate::simulation_plan::SimulationStepType::ImpactAssessment => {
                    step_output.push(format!("Assessed impact for {}", step.title));
                    validation_results.push("Impact assessment complete".to_string());
                }
                crate::simulation_plan::SimulationStepType::ChangeApplication => {
                    step_output.push(format!("Applied changes for {}", step.title));
                    validation_results.push("Changes applied successfully".to_string());
                }
                crate::simulation_plan::SimulationStepType::Validation => {
                    step_output.push(format!("Validated {}", step.title));
                    validation_results.push("Validation complete".to_string());
                }
                crate::simulation_plan::SimulationStepType::Custom(_) => {
                    step_output.push(format!("Executed custom step: {}", step.title));
                    validation_results.push("Custom step complete".to_string());
                }
            }

            // Add mock warnings for critical steps
            if step.is_critical {
                warnings.push(format!(
                    "Critical step {} completed successfully",
                    step.title
                ));
            }

            // Check validation criteria
            for criterion in &step.validation_criteria {
                // Mock validation - in real implementation this would check actual criteria
                validation_results.push(format!("Validated: {}", criterion));
            }

            let step_time = step_start.elapsed().as_millis() as u64;

            let step_result = StepExecutionResult {
                step_id: step.id,
                phase: step.phase.clone(),
                success: step_success,
                execution_time_ms: step_time,
                output: step_output,
                errors: step_errors,
                validation_results,
            };

            step_results.push(step_result);

            if !step_success && step.is_critical {
                success = false;
                errors.push(format!("Critical step {} failed", step.title));
                break;
            }
        }

        let total_time = start_time.elapsed().as_millis() as u64;

        Ok(SimulationExecutionResult {
            id: execution_id,
            plan: plan.clone(),
            step_results,
            success,
            execution_time_ms: total_time,
            errors,
            warnings,
        })
    }

    /// Validate a change request
    pub async fn validate_change(
        &self,
        change_request: &ChangeRequest,
        code_graph: &CodeGraph,
    ) -> CoreResult<crate::reasoning_engine::ValidationResult> {
        self.reasoning_engine
            .validate_change(change_request, code_graph)
            .await
            .map_err(|e| CoreError::ResourceNotFound(format!("Validation failed: {:?}", e)))
    }

    /// Get reasoning about a change
    pub async fn reason_about_change(
        &self,
        change_request: &ChangeRequest,
        code_graph: &CodeGraph,
    ) -> CoreResult<ReasoningResult> {
        self.reasoning_engine
            .reason_about_change(change_request, code_graph)
            .await
            .map_err(|e| CoreError::ResourceNotFound(format!("Reasoning failed: {:?}", e)))
    }

    /// Analyze change impact
    pub async fn analyze_change_impact(
        &self,
        change_request: &ChangeRequest,
        code_graph: &CodeGraph,
    ) -> CoreResult<GraphAnalysisResult> {
        self.graph_analyzer
            .analyze_change_impact(change_request, code_graph)
            .await
            .map_err(|e| CoreError::ResourceNotFound(format!("Impact analysis failed: {:?}", e)))
    }

    /// Generate debugging information
    pub async fn generate_debugging_info(
        &self,
        change_request: &ChangeRequest,
        simulation_plan: &SimulationPlan,
        confidence_score: Option<&ConfidenceScore>,
    ) -> CoreResult<DebuggingInfo> {
        self.debugging_generator
            .generate_debugging_info(change_request, simulation_plan, confidence_score)
            .await
            .map_err(|e| {
                CoreError::ResourceNotFound(format!("Debugging generation failed: {:?}", e))
            })
    }

    /// Estimate memory usage for a simulation
    pub fn estimate_memory_usage(
        &self,
        change_request: &ChangeRequest,
        code_graph: &CodeGraph,
    ) -> usize {
        // Base memory usage
        let mut base_usage = 1024 * 1024; // 1MB base

        // Add memory for change request
        base_usage += change_request.description.len() * 2;
        base_usage += change_request.current_code.len() * 2;
        base_usage += change_request.proposed_code.len() * 2;

        // Add memory for code graph
        let node_count = code_graph.node_count();
        base_usage += node_count * 1024; // Estimate per node

        // Add memory for reasoning results
        base_usage += 10 * 1024 * 1024; // 10MB for reasoning

        // Add memory for graph analysis
        base_usage += 5 * 1024 * 1024; // 5MB for graph analysis

        // Add memory for simulation plan
        base_usage += 2 * 1024 * 1024; // 2MB for simulation plan

        // Add memory for debugging info
        if self.config.auto_generate_debugging {
            base_usage += 3 * 1024 * 1024; // 3MB for debugging info
        }

        base_usage
    }

    /// Check if this sorcerer uses custom dependencies
    pub fn is_custom(&self) -> bool {
        self.is_custom
    }

    /// Get current configuration
    pub fn config(&self) -> &SorcererConfig {
        &self.config
    }

    /// Update configuration
    pub fn update_config(&mut self, config: SorcererConfig) {
        self.config = config;
    }

    /// Get reasoning engine name
    pub fn reasoning_engine_name(&self) -> &'static str {
        self.reasoning_engine.name()
    }

    /// Get reasoning engine capabilities
    pub fn reasoning_engine_capabilities(&self) -> crate::reasoning_engine::ReasoningCapabilities {
        self.reasoning_engine.capabilities()
    }
}

impl Default for CozoCodeSimulationSorcerer {
    fn default() -> Self {
        Self::new()
    }
}

impl SimulationResult {
    /// Check if the result has a simulation plan
    pub fn has_simulation_plan(&self) -> bool {
        !self.simulation_plan.steps().is_empty()
    }

    /// Check if the result has a confidence score
    pub fn has_confidence_score(&self) -> bool {
        self.confidence_score.score() >= 0.0
    }

    /// Check if the result has debugging info
    pub fn has_debugging_info(&self) -> bool {
        self.debugging_info.is_some()
    }

    /// Check if confidence meets threshold
    pub fn confidence_meets_threshold(&self, threshold: f64) -> bool {
        self.confidence_score.meets_threshold(threshold)
    }

    /// Get the simulation plan
    pub fn plan(&self) -> &SimulationPlan {
        &self.simulation_plan
    }

    /// Get the confidence score
    pub fn confidence(&self) -> &ConfidenceScore {
        &self.confidence_score
    }

    /// Export debugging artifacts
    pub fn export_debugging_artifacts(&self) -> CoreResult<Option<HashMap<String, String>>> {
        match &self.debugging_info {
            Some(debugging_info) => Ok(Some(debugging_info.export_artifacts()?)),
            None => Ok(None),
        }
    }
}

impl SimulationExecutionResult {
    /// Get all execution steps
    pub fn execution_steps(&self) -> &[StepExecutionResult] {
        &self.step_results
    }

    /// Check if execution was successful
    pub fn is_success(&self) -> bool {
        self.success
    }

    /// Get total execution time
    pub fn execution_time(&self) -> std::time::Duration {
        std::time::Duration::from_millis(self.execution_time_ms)
    }

    /// Get steps that failed
    pub fn failed_steps(&self) -> Vec<&StepExecutionResult> {
        self.step_results
            .iter()
            .filter(|step| !step.success)
            .collect()
    }

    /// Get steps that succeeded
    pub fn successful_steps(&self) -> Vec<&StepExecutionResult> {
        self.step_results
            .iter()
            .filter(|step| step.success)
            .collect()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::change_request::{ChangeType, Complexity};
    use parseltongue_01::{streaming::CodeNode, types::ISGL1Key};
    use std::path::PathBuf;

    fn create_test_change_request() -> ChangeRequest {
        let key = ISGL1Key::new(
            PathBuf::from("/test/src/lib.rs"),
            "lib.rs".to_string(),
            "test_function".to_string(),
        );

        ChangeRequest::new(
            key,
            ChangeType::Modify,
            "Add error handling".to_string(),
            "fn test_function() {}".to_string(),
            "fn test_function() -> Result<(), Error> { Ok(()) }".to_string(),
        )
        .with_complexity(Complexity::Moderate)
    }

    fn create_test_code_graph() -> CodeGraph {
        let mut graph = CodeGraph::new();
        let key = ISGL1Key::new(
            PathBuf::from("/test/src/lib.rs"),
            "lib.rs".to_string(),
            "test_function".to_string(),
        );
        let node = CodeNode {
            current_code: "fn test_function() {}".to_string(),
            future_code: None,
            interface_signature: Some("fn test_function()".to_string()),
            tdd_classification: Some("unit_test".to_string()),
            current_id: 1,
            future_id: 1,
            lsp_meta_data: None,
        };
        graph.insert_node(key, node).unwrap();
        graph
    }

    #[tokio::test]
    async fn test_sorcerer_creation() {
        let sorcerer = CozoCodeSimulationSorcerer::new();
        assert_eq!(sorcerer.config.default_confidence_threshold, 0.8);
        assert!(sorcerer.config.strict_confidence_enforcement);
        assert_eq!(sorcerer.reasoning_engine_name(), "mock_reasoning_engine");
    }

    #[tokio::test]
    async fn test_simulate_change() {
        let mut sorcerer = CozoCodeSimulationSorcerer::new();
        let change_request = create_test_change_request();
        let code_graph = create_test_code_graph();

        let result = sorcerer
            .simulate_change(&change_request, &code_graph)
            .await
            .unwrap();

        assert_eq!(
            result.change_request.description,
            change_request.description
        );
        assert!(result.has_simulation_plan());
        assert!(result.has_confidence_score());
        assert!(result.has_debugging_info());
        assert_eq!(result.status, SimulationStatus::Completed);
        assert!(result.confidence_meets_threshold(0.8));
    }

    #[tokio::test]
    async fn test_generate_simulation_plan() {
        let mut sorcerer = CozoCodeSimulationSorcerer::new();
        let change_request = create_test_change_request();
        let code_graph = create_test_code_graph();

        let plan = sorcerer
            .generate_simulation_plan(&change_request, &code_graph)
            .await
            .unwrap();

        assert!(!plan.steps().is_empty());
        assert_eq!(plan.steps_by_phase("A").len(), 2);
        assert_eq!(plan.steps_by_phase("B").len(), 2);
        assert_eq!(plan.steps_by_phase("C").len(), 1);
        assert_eq!(plan.steps_by_phase("D").len(), 1);
    }

    #[tokio::test]
    async fn test_execute_simulation_plan() {
        let sorcerer = CozoCodeSimulationSorcerer::new();
        let plan = crate::SimulationPlan::mock();

        let result = sorcerer.execute_simulation_plan(&plan).await.unwrap();

        assert!(result.is_success());
        assert_eq!(result.execution_steps().len(), plan.steps().len());
        assert!(result.execution_time().as_millis() > 0);
    }

    #[tokio::test]
    async fn test_validate_change() {
        let sorcerer = CozoCodeSimulationSorcerer::new();
        let change_request = create_test_change_request();
        let code_graph = create_test_code_graph();

        let result = sorcerer
            .validate_change(&change_request, &code_graph)
            .await
            .unwrap();

        assert!(result.is_valid);
    }

    #[tokio::test]
    async fn test_invalid_change_request() {
        let mut sorcerer = CozoCodeSimulationSorcerer::new();
        let mut invalid_request = create_test_change_request();
        invalid_request.description = String::new(); // Empty description
        invalid_request.proposed_code = String::new(); // Empty proposed code

        let code_graph = create_test_code_graph();

        let result = sorcerer
            .simulate_change(&invalid_request, &code_graph)
            .await;
        assert!(result.is_err());
    }

    #[tokio::test]
    async fn test_memory_usage_estimation() {
        let sorcerer = CozoCodeSimulationSorcerer::new();
        let change_request = create_test_change_request();
        let code_graph = create_test_code_graph();

        let memory_usage = sorcerer.estimate_memory_usage(&change_request, &code_graph);
        assert!(memory_usage > 0);
        assert!(memory_usage < 1024 * 1024 * 1024); // Should be less than 1GB
    }

    #[tokio::test]
    async fn test_custom_dependencies() {
        let custom_reasoning = crate::reasoning_engine::MockReasoningEngine::default();
        let custom_analyzer = GraphAnalyzer::new();

        let sorcerer =
            CozoCodeSimulationSorcerer::with_dependencies(custom_reasoning, custom_analyzer);

        assert!(sorcerer.is_custom());
    }

    #[tokio::test]
    async fn test_configuration_update() {
        let mut sorcerer = CozoCodeSimulationSorcerer::new();
        let mut config = sorcerer.config().clone();
        config.default_confidence_threshold = 0.9;

        sorcerer.update_config(config);
        assert_eq!(sorcerer.config().default_confidence_threshold, 0.9);
    }

    #[tokio::test]
    async fn test_simulation_result() {
        let change_request = create_test_change_request();
        let simulation_plan = crate::SimulationPlan::mock();
        let reasoning_result = crate::reasoning_engine::MockReasoningEngine::default()
            .reason_about_change(&change_request, &create_test_code_graph())
            .await
            .unwrap();
        let graph_analysis = GraphAnalyzer::new()
            .analyze_change_impact(&change_request, &create_test_code_graph())
            .await
            .unwrap();
        let confidence_score = ConfidenceScore::new(0.85, "Test confidence".to_string());
        let debugging_info = DebuggingInfoGenerator::new()
            .generate_debugging_info(&change_request, &simulation_plan, Some(&confidence_score))
            .await
            .unwrap();

        let result = SimulationResult {
            id: Uuid::new_v4(),
            change_request,
            simulation_plan,
            reasoning_result,
            graph_analysis,
            confidence_score,
            debugging_info: Some(debugging_info),
            status: SimulationStatus::Completed,
            metadata: SimulationMetadata {
                started_at: chrono::Utc::now(),
                completed_at: Some(chrono::Utc::now()),
                execution_time_ms: Some(1000),
                memory_usage_bytes: None,
                steps_executed: 6,
                steps_failed: 0,
                warnings: vec![],
            },
        };

        assert!(result.has_simulation_plan());
        assert!(result.has_confidence_score());
        assert!(result.has_debugging_info());
        assert!(result.confidence_meets_threshold(0.8));

        let artifacts = result.export_debugging_artifacts().unwrap();
        assert!(artifacts.is_some());
        assert!(artifacts.unwrap().contains_key("debugging_summary.md"));
    }

    #[tokio::test]
    async fn test_execution_result() {
        let plan = crate::SimulationPlan::mock();
        let step_results = vec![
            StepExecutionResult {
                step_id: Uuid::new_v4(),
                phase: "A01".to_string(),
                success: true,
                execution_time_ms: 100,
                output: vec!["Analysis complete".to_string()],
                errors: vec![],
                validation_results: vec!["Valid".to_string()],
            },
            StepExecutionResult {
                step_id: Uuid::new_v4(),
                phase: "B01".to_string(),
                success: true,
                execution_time_ms: 150,
                output: vec!["Impact assessed".to_string()],
                errors: vec![],
                validation_results: vec!["Valid".to_string()],
            },
        ];

        let result = SimulationExecutionResult {
            id: Uuid::new_v4(),
            plan,
            step_results,
            success: true,
            execution_time_ms: 250,
            errors: vec![],
            warnings: vec![],
        };

        assert!(result.is_success());
        assert_eq!(result.execution_steps().len(), 2);
        assert_eq!(result.successful_steps().len(), 2);
        assert_eq!(result.failed_steps().len(), 0);
        assert_eq!(result.execution_time().as_millis(), 250);
    }

    #[test]
    fn test_default_sorcerer() {
        let sorcerer = CozoCodeSimulationSorcerer::default();
        assert_eq!(sorcerer.config.default_confidence_threshold, 0.8);
    }
}
