=== /home/amuldotexe/Desktop/GitHub202410/parseltongue/phase01/src/storage/db.rs ===
//! Database Storage Implementation
//! 
//! Pyramid Structure:
//! 
//! Level 4 (Top): Database Operations
//! - DatabaseStorage   (main storage implementation)
//! - BatchProcessor    (batch operation handling)
//! - MetricsCollector  (storage metrics)
//! 
//! Level 3: Transaction Management
//! - TransactionManager (manages transactions)
//! - TransactionMetrics (transaction monitoring)
//! - ErrorRecovery     (handles failures)
//! 
//! Level 2: Connection Management
//! - ConnectionPool    (manages connections)
//! - ConnectionMetrics (connection monitoring)
//! - PoolConfig       (pool configuration)
//! 
//! Level 1 (Base): Core Database Types
//! - DbConfig         (database configuration)
//! - DbError          (database errors)
//! - ConnectionInfo   (connection details)

use std::sync::Arc;
use tokio::sync::{Semaphore, RwLock};
use sled::{Db, Tree};
use bytes::Bytes;
use metrics::{Counter, Gauge, Histogram};
use crate::core::{error::{Error, Result}, types::*};
use super::{AsyncStorage, StorageConfig};

// ===== Level 1: Core Database Types =====
// Design Choice: Using sled for embedded storage

/// Database metrics collection
#[derive(Debug)]
struct DbMetrics {
    writes: Counter,
    reads: Counter,
    active_transactions: Gauge,
    transaction_duration: Histogram,
}

impl DbMetrics {
    fn new() -> Self {
        Self {
            writes: Counter::new(),
            reads: Counter::new(),
            active_transactions: Gauge::new(),
            transaction_duration: Histogram::new(),
        }
    }
}

// ===== Level 2: Connection Management =====
// Design Choice: Using connection pooling

/// Database storage implementation
pub struct DatabaseStorage {
    /// Sled database instance
    db: Arc<Db>,
    /// Main data tree
    data_tree: Arc<Tree>,
    /// Connection pool
    pool: Arc<Semaphore>,
    /// Transaction manager
    transactions: Arc<TransactionManager>,
    /// Database metrics
    metrics: DbMetrics,
}

impl DatabaseStorage {
    /// Creates new database storage
    pub fn new(config: StorageConfig) -> Result<Self> {
        let db = sled::open(&config.path)?;
        let data_tree = db.open_tree("data")?;
        let pool = Arc::new(Semaphore::new(config.pool_size));
        let transactions = Arc::new(TransactionManager::new());
        let metrics = DbMetrics::new();

        Ok(Self {
            db: Arc::new(db),
            data_tree: Arc::new(data_tree),
            pool,
            transactions,
            metrics,
        })
    }

    /// Executes operation with connection from pool
    async fn with_connection<F, R>(&self, f: F) -> Result<R>
    where
        F: FnOnce() -> Result<R> + Send + 'static,
        R: Send + 'static,
    {
        let _permit = self.pool.acquire().await?;
        let start = std::time::Instant::now();
        
        self.metrics.active_transactions.increment(1.0);
        
        let result = tokio::task::spawn_blocking(f)
            .await
            .map_err(|e| Error::Runtime(e.to_string()))??;

        self.metrics.active_transactions.decrement(1.0);
        self.metrics.transaction_duration.record(start.elapsed());
        
        Ok(result)
    }
}

// ===== Level 3: Transaction Management =====
// Design Choice: Using ACID transactions

/// Transaction manager implementation
struct TransactionManager {
    active_transactions: Arc<RwLock<Vec<TransactionId>>>,
}

impl TransactionManager {
    fn new() -> Self {
        Self {
            active_transactions: Arc::new(RwLock::new(Vec::new())),
        }
    }

    async fn begin(&self) -> TransactionId {
        let id = TransactionId::new();
        self.active_transactions.write().await.push(id);
        id
    }

    async fn commit(&self, id: TransactionId) {
        let mut transactions = self.active_transactions.write().await;
        if let Some(pos) = transactions.iter().position(|x| *x == id) {
            transactions.remove(pos);
        }
    }
}

// ===== Level 4: Database Operations =====
// Design Choice: Using async traits for storage operations

#[async_trait::async_trait]
impl AsyncStorage for DatabaseStorage {
    async fn store(&self, key: &str, data: Bytes) -> Result<()> {
        let key = key.to_string();
        let data = data.to_vec();
        
        self.with_connection(move || {
            self.data_tree.insert(key.as_bytes(), data)?;
            self.data_tree.flush()?;
            Ok(())
        }).await
    }

    async fn batch_store(&self, entries: Vec<(String, Bytes)>) -> Result<()> {
        self.with_connection(move || {
            let batch = sled::Batch::default();
            
            for (key, data) in entries {
                batch.insert(key.as_bytes(), data.to_vec());
            }
            
            self.data_tree.apply_batch(batch)?;
            self.data_tree.flush()?;
            Ok(())
        }).await
    }

    async fn get(&self, key: &str) -> Result<Option<Bytes>> {
        let key = key.to_string();
        
        self.with_connection(move || {
            Ok(self.data_tree.get(key.as_bytes())?
                .map(|v| Bytes::from(v.to_vec())))
        }).await
    }
}

/// Transaction identifier
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
struct TransactionId(u64);

impl TransactionId {
    fn new() -> Self {
        use std::sync::atomic::{AtomicU64, Ordering};
        static NEXT_ID: AtomicU64 = AtomicU64::new(0);
        Self(NEXT_ID.fetch_add(1, Ordering::SeqCst))
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::TempDir;

    #[tokio::test]
    async fn test_database_operations() {
        let temp_dir = TempDir::new().unwrap();
        
        let config = StorageConfig {
            path: temp_dir.path().to_path_buf(),
            pool_size: 4,
            batch_size: 100,
            index_config: IndexConfig::default(),
        };

        let storage = DatabaseStorage::new(config).unwrap();

        // Test store and retrieve
        let key = "test-key";
        let data = Bytes::from("test-data");
        
        storage.store(key, data.clone()).await.unwrap();
        let retrieved = storage.get(key).await.unwrap();
        
        assert_eq!(retrieved, Some(data));

        // Test batch store
        let entries = vec![
            ("key1".to_string(), Bytes::from("data1")),
            ("key2".to_string(), Bytes::from("data2")),
        ];
        
        assert!(storage.batch_store(entries).await.is_ok());
    }
}
-e 

=== /home/amuldotexe/Desktop/GitHub202410/parseltongue/phase01/src/storage/mod.rs ===
//! Storage Layer Coordination
//! 
//! Pyramid Structure:
//! 
//! Level 4 (Top): Storage Orchestration
//! - Storage Orchestration
//! - StorageMetrics    (aggregates storage performance)
//! - ConnectionPool    (manages DB connections)
//! 
//! Level 3: Operation Management
//! - BatchProcessor    (handles batch operations)
//! - TransactionManager (manages transactions)
//! - IndexCoordinator  (coordinates indexing)
//! 
//! Level 2: Storage Traits
//! - AsyncStorage      (async storage interface)
//! - StorageBackend    (storage implementation)
//! - IndexManager      (index management)
//! 
//! Level 1 (Base): Core Storage Types
//! - StorageConfig    (storage configuration)
//! - StorageError     (storage-specific errors)
//! - ConnectionConfig (connection settings)

use std::path::{Path, PathBuf};
use std::sync::Arc;
use tokio::sync::{Semaphore, RwLock};
use bytes::Bytes;
use metrics::{Counter, Gauge, Histogram};
use crate::core::{error::{Error, Result}, types::*};

pub mod db;
pub mod index;

// Re-export main types
pub use db::DatabaseStorage;
pub use index::IndexManager;

// ===== Level 1: Core Storage Types =====
// Design Choice: Using builder pattern for configuration

/// Storage configuration
#[derive(Debug, Clone)]
pub struct StorageConfig {
    /// Base storage path
    pub path: PathBuf,
    /// Connection pool size
    pub pool_size: usize,
    /// Batch size for operations
    pub batch_size: usize,
    /// Index configuration
    pub index_config: IndexConfig,
}

impl StorageConfig {
    /// Creates new storage configuration
    pub fn new(path: impl AsRef<Path>) -> Self {
        Self {
            path: path.as_ref().to_path_buf(),
            pool_size: 4,
            batch_size: 1000,
            index_config: IndexConfig::default(),
        }
    }

    /// Sets the storage path
    pub fn with_path(mut self, path: impl AsRef<Path>) -> Self {
        self.path = path.as_ref().to_path_buf();
        self
    }
}

/// Storage metrics collection
#[derive(Debug)]
struct StorageMetrics {
    operations: Counter,
    active_connections: Gauge,
    operation_duration: Histogram,
    batch_size: Histogram,
}

impl StorageMetrics {
    fn new() -> Self {
        Self {
            operations: Counter::new(),
            active_connections: Gauge::new(),
            operation_duration: Histogram::new(),
            batch_size: Histogram::new(),
        }
    }
}

// ===== Level 2: Storage Traits =====
// Design Choice: Using async traits for storage operations

/// Async storage interface
#[async_trait::async_trait]
pub trait AsyncStorage: Send + Sync + 'static {
    /// Store data with key
    async fn store(&self, key: &str, data: Bytes) -> Result<()>;
    
    /// Batch store multiple entries
    async fn batch_store(&self, entries: Vec<(String, Bytes)>) -> Result<()>;
    
    /// Retrieve data by key
    async fn get(&self, key: &str) -> Result<Option<Bytes>>;
}

// ===== Level 3: Operation Management =====
// Design Choice: Using connection pooling and batch processing

/// Storage manager implementation
pub struct StorageManager {
    /// Storage backend
    storage: Arc<DatabaseStorage>,
    /// Index manager
    index: Arc<IndexManager>,
    /// Connection pool
    pool: Arc<Semaphore>,
    /// Batch processor
    batch_processor: Arc<BatchProcessor>,
    /// Storage metrics
    metrics: StorageMetrics,
}

impl StorageManager {
    /// Creates new storage manager
    pub async fn new(config: StorageConfig) -> Result<Self> {
        let storage = Arc::new(DatabaseStorage::new(&config)?);
        let index = Arc::new(IndexManager::new(storage.clone(), config.index_config)?);
        let pool = Arc::new(Semaphore::new(config.pool_size));
        let batch_processor = Arc::new(BatchProcessor::new(config.batch_size));
        let metrics = StorageMetrics::new();

        Ok(Self {
            storage,
            index,
            pool,
            batch_processor,
            metrics,
        })
    }

    /// Opens storage at path
    pub async fn open(path: impl AsRef<Path>) -> Result<Self> {
        let config = StorageConfig::new(path);
        Self::new(config).await
    }

    /// Stores data with key
    pub async fn store(&self, key: String, data: Bytes) -> Result<()> {
        let _permit = self.pool.acquire().await?;
        let start = std::time::Instant::now();

        self.metrics.active_connections.increment(1.0);
        
        let result = self.storage.store(&key, data.clone()).await;
        
        if result.is_ok() {
            self.index.update(&key, IndexEntry::new(&key, &data)).await?;
            self.metrics.operations.increment(1);
            self.metrics.operation_duration.record(start.elapsed());
        }

        self.metrics.active_connections.decrement(1.0);
        result
    }

    /// Batch stores multiple entries
    pub async fn batch_store(&self, entries: Vec<(String, Bytes)>) -> Result<()> {
        let _permit = self.pool.acquire().await?;
        let start = std::time::Instant::now();

        self.metrics.active_connections.increment(1.0);
        self.metrics.batch_size.record(entries.len() as f64);

        let result = self.batch_processor.process(entries, |batch| {
            async move {
                self.storage.batch_store(batch).await?;
                Ok(())
            }
        }).await;

        self.metrics.active_connections.decrement(1.0);
        self.metrics.operation_duration.record(start.elapsed());
        
        result
    }
}

// ===== Level 4: Storage Orchestration =====
// Design Choice: Using batch processing for efficiency

/// Batch processor implementation
struct BatchProcessor {
    batch_size: usize,
}

impl BatchProcessor {
    fn new(batch_size: usize) -> Self {
        Self { batch_size }
    }

    async fn process<T, F, Fut>(&self, items: Vec<T>, f: F) -> Result<()>
    where
        F: Fn(Vec<T>) -> Fut,
        Fut: std::future::Future<Output = Result<()>>,
    {
        for chunk in items.chunks(self.batch_size) {
            f(chunk.to_vec()).await?;
        }
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::TempDir;

    #[tokio::test]
    async fn test_storage_operations() {
        let temp_dir = TempDir::new().unwrap();
        
        // Test both ways of creating storage
        let storage1 = StorageManager::open(temp_dir.path()).await.unwrap();
        
        let config = StorageConfig::new(temp_dir.path())
            .with_path(temp_dir.path().join("storage"));
        let storage2 = StorageManager::new(config).await.unwrap();

        // Test operations
        let key = "test-key".to_string();
        let data = Bytes::from("test-data");
        
        assert!(storage1.store(key.clone(), data.clone()).await.is_ok());
        assert!(storage2.store(key, data).await.is_ok());
    }
}
-e 

=== /home/amuldotexe/Desktop/GitHub202410/parseltongue/phase01/src/storage/index.rs ===
//! Storage Index Management
//! 
//! Pyramid Structure:
//! 
//! Level 4 (Top): Index Operations
//! - IndexManager     (manages indices)
//! - IndexMetrics     (tracks index performance)
//! - SearchOptimizer  (optimizes searches)
//! 
//! Level 3: Index Maintenance
//! - IndexUpdater     (handles updates)
//! - IndexCompactor   (manages compaction)
//! - IndexValidator   (validates integrity)
//! 
//! Level 2: Index Implementation
//! - IndexTree        (tree implementation)
//! - IndexIterator    (index traversal)
//! - IndexCache       (caching layer)
//! 
//! Level 1 (Base): Core Index Types
//! - IndexConfig      (index configuration)
//! - IndexEntry       (index entry type)
//! - IndexError       (index-specific errors)

use std::sync::Arc;
use tokio::sync::RwLock;
use sled::Tree;
use bytes::Bytes;
use metrics::{Counter, Gauge, Histogram};
use crate::core::{error::{Error, Result}, types::*};
use super::DatabaseStorage;

// ===== Level 1: Core Index Types =====
// Design Choice: Using RwLock for concurrent access

/// Index configuration
#[derive(Debug, Clone, Default)]
pub struct IndexConfig {
    /// Cache size
    pub cache_size: usize,
    /// Flush threshold
    pub flush_threshold: usize,
    /// Enable compression
    pub compression_enabled: bool,
}

/// Index metrics collection
#[derive(Debug)]
struct IndexMetrics {
    updates: Counter,
    searches: Counter,
    cache_hits: Counter,
    cache_misses: Counter,
}

impl IndexMetrics {
    fn new() -> Self {
        Self {
            updates: Counter::new(),
            searches: Counter::new(),
            cache_hits: Counter::new(),
            cache_misses: Counter::new(),
        }
    }
}

// ===== Level 2: Index Implementation =====
// Design Choice: Using LRU cache for performance

/// Index entry representation
#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct IndexEntry {
    /// Entry path
    pub path: std::path::PathBuf,
    /// Entry size
    pub size: u64,
    /// Entry timestamp
    pub timestamp: chrono::DateTime<chrono::Utc>,
}

impl IndexEntry {
    pub fn new(path: &str, data: &Bytes) -> Self {
        Self {
            path: path.into(),
            size: data.len() as u64,
            timestamp: chrono::Utc::now(),
        }
    }
}

/// Index manager implementation
pub struct IndexManager {
    /// Storage backend
    storage: Arc<DatabaseStorage>,
    /// Index tree
    tree: Arc<Tree>,
    /// Index cache
    cache: Arc<RwLock<lru::LruCache<String, IndexEntry>>>,
    /// Index metrics
    metrics: IndexMetrics,
}

impl IndexManager {
    /// Creates new index manager
    pub fn new(storage: Arc<DatabaseStorage>, config: IndexConfig) -> Result<Self> {
        let tree = storage.db().open_tree("index")?;
        let cache = Arc::new(RwLock::new(
            lru::LruCache::new(config.cache_size)
        ));
        let metrics = IndexMetrics::new();

        Ok(Self {
            storage,
            tree: Arc::new(tree),
            cache,
            metrics,
        })
    }

    // ===== Level 3: Index Maintenance =====
    // Design Choice: Using batched updates for efficiency

    /// Updates index entry
    pub async fn update(&self, key: &str, entry: IndexEntry) -> Result<()> {
        // Update cache
        self.cache.write().await.put(
            key.to_string(), 
            entry.clone()
        );

        // Update tree
        self.tree.insert(
            key.as_bytes(),
            bincode::serialize(&entry)?
        )?;

        self.metrics.updates.increment(1);
        Ok(())
    }

    /// Searches index
    pub async fn search(&self, prefix: &str) -> Result<Vec<IndexEntry>> {
        self.metrics.searches.increment(1);
        
        let mut results = Vec::new();
        
        // Check cache first
        {
            let cache = self.cache.read().await;
            if let Some(entry) = cache.get(prefix) {
                self.metrics.cache_hits.increment(1);
                results.push(entry.clone());
                return Ok(results);
            }
        }
        
        self.metrics.cache_misses.increment(1);

        // Search tree
        for item in self.tree.scan_prefix(prefix.as_bytes()) {
            let (_, value) = item?;
            let entry: IndexEntry = bincode::deserialize(&value)?;
            results.push(entry);
        }

        Ok(results)
    }

    // ===== Level 4: Index Operations =====
    // Design Choice: Using async compaction

    /// Compacts index
    pub async fn compact(&self) -> Result<()> {
        self.tree.flush()?;
        self.tree.compact_range::<&[u8], &[u8]>(None, None)?;
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::TempDir;

    #[tokio::test]
    async fn test_index_operations() {
        let temp_dir = TempDir::new().unwrap();
        let config = StorageConfig {
            path: temp_dir.path().to_path_buf(),
            pool_size: 4,
            batch_size: 100,
            index_config: IndexConfig::default(),
        };

        let storage = Arc::new(DatabaseStorage::new(config.clone()).unwrap());
        let index = IndexManager::new(storage, config.index_config).unwrap();

        // Test index operations
        let entry = IndexEntry::new("test/path", &Bytes::from("test"));
        
        index.update("test-key", entry.clone()).await.unwrap();
        let results = index.search("test").await.unwrap();
        
        assert_eq!(results.len(), 1);
        assert_eq!(results[0].path, entry.path);
    }
}
-e 

=== /home/amuldotexe/Desktop/GitHub202410/parseltongue/phase01/src/lib.rs ===
//! ZIP File Analysis and Storage Library
//! 
//! Pyramid Structure:
//! 
//! Level 4 (Top): Public API
//! - ZipAnalyzer      (main public interface)
//! - StorageManager   (storage interface)
//! - MetricsCollector (metrics interface)
//! 
//! Level 3: Feature Modules
//! - ZIP Processing   (streaming, validation)
//! - Storage Layer    (database, indexing)
//! - Metrics System   (collection, reporting)
//! 
//! Level 2: Core Infrastructure
//! - Async Runtime    (worker management)
//! - Error Handling   (error types)
//! - Resource Control (pooling, limits)
//! 
//! Level 1 (Base): Utility Layer
//! - Buffer Management (streaming buffers)
//! - Resource Cleanup (RAII guards)
//! - Type Definitions (core types)

// Re-export main modules
pub mod core;
pub mod cli;
pub mod storage;
pub mod zip;
pub mod utils;
pub mod metrics;

// Re-export main types for public API
pub use crate::{
    zip::{ZipProcessor, ZipConfig, ZipEntry},
    storage::{StorageManager, StorageConfig},
    metrics::{MetricsManager, MetricsConfig},
    core::{error::{Error, Result}, types::*},
};

// ===== Level 1: Core Types =====
// Design Choice: Using type aliases for common types

/// Byte buffer type
pub type Buffer = bytes::Bytes;

/// Path type
pub type Path = std::path::PathBuf;

// ===== Level 2: Core Traits =====
// Design Choice: Using async traits for main operations

/// ZIP analysis interface
#[async_trait::async_trait]
pub trait ZipAnalysis: Send + Sync + 'static {
    /// Analyzes ZIP file
    async fn analyze(&self, path: &Path) -> Result<AnalysisResult>;
    /// Gets analysis metrics
    async fn metrics(&self) -> Result<AnalysisMetrics>;
}

/// Analysis result type
#[derive(Debug, Clone, serde::Serialize)]
pub struct AnalysisResult {
    /// Total entries processed
    pub entries: usize,
    /// Total bytes processed
    pub bytes: u64,
    /// Processing duration
    pub duration: std::time::Duration,
}

/// Analysis metrics type
#[derive(Debug, Clone, serde::Serialize)]
pub struct AnalysisMetrics {
    /// Processing throughput
    pub throughput: f64,
    /// Memory usage
    pub memory_usage: u64,
    /// Error count
    pub errors: u64,
}

// ===== Level 3: Main Implementation =====
// Design Choice: Using builder pattern for configuration

/// ZIP analyzer implementation
pub struct ZipAnalyzer {
    /// ZIP processor
    processor: Arc<ZipProcessor>,
    /// Storage manager
    storage: Arc<StorageManager>,
    /// Metrics manager
    metrics: Arc<MetricsManager>,
}

impl ZipAnalyzer {
    /// Creates new ZIP analyzer
    pub async fn new(config: AnalyzerConfig) -> Result<Self> {
        // Initialize storage
        let storage = Arc::new(StorageManager::new(config.storage).await?);
        
        // Initialize processor
        let processor = Arc::new(ZipProcessor::new(
            config.zip,
            storage.clone(),
        ));
        
        // Initialize metrics
        let metrics = Arc::new(MetricsManager::new(config.metrics));

        Ok(Self {
            processor,
            storage,
            metrics,
        })
    }

    /// Processes ZIP file
    pub async fn process(&self, path: impl AsRef<Path>) -> Result<AnalysisResult> {
        // Start metrics collection
        self.metrics.start().await?;

        // Open and process file
        let file = tokio::fs::File::open(path.as_ref()).await?;
        let start = std::time::Instant::now();
        
        self.processor.process(file).await?;

        // Build result
        let result = AnalysisResult {
            entries: self.metrics.get_counter("entries_processed").await?,
            bytes: self.metrics.get_counter("bytes_processed").await?,
            duration: start.elapsed(),
        };

        // Stop metrics collection
        self.metrics.stop().await?;

        Ok(result)
    }
}

// ===== Level 4: Configuration =====
// Design Choice: Using separate configs for components

/// Analyzer configuration
#[derive(Debug, Clone)]
pub struct AnalyzerConfig {
    /// ZIP configuration
    pub zip: ZipConfig,
    /// Storage configuration
    pub storage: StorageConfig,
    /// Metrics configuration
    pub metrics: MetricsConfig,
}

impl Default for AnalyzerConfig {
    fn default() -> Self {
        Self {
            zip: ZipConfig::default(),
            storage: StorageConfig {
                path: "storage".into(),
                pool_size: 4,
                batch_size: 1000,
                index_config: Default::default(),
            },
            metrics: MetricsConfig::default(),
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::TempDir;

    #[tokio::test]
    async fn test_analyzer() {
        let temp_dir = TempDir::new().unwrap();
        
        let config = AnalyzerConfig {
            storage: StorageConfig {
                path: temp_dir.path().to_path_buf(),
                pool_size: 4,
                batch_size: 100,
                index_config: Default::default(),
            },
            ..Default::default()
        };

        let analyzer = ZipAnalyzer::new(config).await.unwrap();
        
        // Create test ZIP
        let zip_path = temp_dir.path().join("test.zip");
        let mut zip = zip::ZipWriter::new(std::fs::File::create(&zip_path).unwrap());
        
        zip.start_file("test.txt", Default::default()).unwrap();
        zip.write_all(b"test data").unwrap();
        zip.finish().unwrap();

        // Process ZIP
        let result = analyzer.process(&zip_path).await.unwrap();
        
        assert_eq!(result.entries, 1);
        assert_eq!(result.bytes, 9); // "test data".len()
    }
}
-e 

=== /home/amuldotexe/Desktop/GitHub202410/parseltongue/phase01/src/metrics/report.rs ===
//! Metrics Reporting Implementation
//! 
//! Pyramid Structure:
//! 
//! Level 4 (Top): Report Orchestration
//! - ReportManager     (manages reporting)
//! - ReportMetrics     (tracks reporting)
//! - ExportManager     (manages exports)
//! 
//! Level 3: Report Types
//! - JsonReporter      (JSON format)
//! - PrometheusReporter (Prometheus format)
//! - OpenTelemetryReporter (OpenTelemetry)
//! 
//! Level 2: Report Implementation
//! - AsyncReporter     (async reporting)
//! - ReportState       (report state)
//! - ReportBuffer      (report buffer)
//! 
//! Level 1 (Base): Core Report Types
//! - ReporterConfig    (reporter config)
//! - ReportResult      (result types)
//! - ReportError       (report errors)

use std::sync::Arc;
use tokio::sync::RwLock;
use tokio::time::{Duration, interval};
use metrics::{Counter, Gauge, Histogram};
use serde_json::Value;
use crate::core::error::Result;
use super::{MetricsRegistry, MetricsConfig, MetricsFormat};

// ===== Level 1: Core Report Types =====
// Design Choice: Using serde for serialization

/// Reporter configuration
#[derive(Debug, Clone)]
pub struct ReporterConfig {
    /// Report interval
    pub interval: Duration,
    /// Output format
    pub format: MetricsFormat,
    /// Output path
    pub output_path: std::path::PathBuf,
}

impl Default for ReporterConfig {
    fn default() -> Self {
        Self {
            interval: Duration::from_secs(10),
            format: MetricsFormat::Json,
            output_path: std::path::PathBuf::from("metrics"),
        }
    }
}

// ===== Level 2: Report Implementation =====
// Design Choice: Using async reporting for efficiency

/// Metrics reporter implementation
pub struct MetricsReporter {
    /// Metrics registry
    registry: Arc<RwLock<MetricsRegistry>>,
    /// Reporter configuration
    config: MetricsConfig,
    /// Report task handle
    task: RwLock<Option<tokio::task::JoinHandle<()>>>,
    /// Reporter metrics
    metrics: ReporterMetrics,
}

impl MetricsReporter {
    /// Creates new metrics reporter
    pub fn new(registry: Arc<RwLock<MetricsRegistry>>, config: MetricsConfig) -> Self {
        Self {
            registry,
            config,
            task: RwLock::new(None),
            metrics: ReporterMetrics::new(),
        }
    }

    /// Starts metrics reporting
    pub async fn start(&self) -> Result<()> {
        let mut task = self.task.write().await;
        if task.is_some() {
            return Ok(());
        }

        let registry = self.registry.clone();
        let config = self.config.clone();
        let metrics = self.metrics.clone();

        *task = Some(tokio::spawn(async move {
            let mut interval = interval(config.interval);
            
            loop {
                interval.tick().await;
                metrics.reports.increment(1);
                
                if let Err(e) = Self::report_metrics(&registry, &config).await {
                    metrics.report_errors.increment(1);
                    tracing::error!("Metrics reporting error: {}", e);
                }
            }
        }));

        Ok(())
    }

    /// Stops metrics reporting
    pub async fn stop(&self) -> Result<()> {
        let mut task = self.task.write().await;
        if let Some(handle) = task.take() {
            handle.abort();
        }
        Ok(())
    }

    // ===== Level 3: Report Types =====
    // Design Choice: Using trait-based reporters

    /// Reports metrics in configured format
    async fn report_metrics(registry: &Arc<RwLock<MetricsRegistry>>, config: &MetricsConfig) -> Result<()> {
        let registry = registry.read().await;
        let output_path = config.output_dir.as_path();
        
        match config.format {
            MetricsFormat::Json => Self::report_json(&registry, output_path).await,
            MetricsFormat::Prometheus => Self::report_prometheus(&registry, output_path).await,
            MetricsFormat::OpenTelemetry => Self::report_opentelemetry(&registry).await,
        }
    }

    /// Reports metrics in JSON format
    async fn report_json(registry: &MetricsRegistry, output_dir: impl AsRef<Path>) -> Result<()> {
        let output_dir = output_dir.as_ref();
        let json = serde_json::to_value(registry)?;
        let path = output_dir.join(format!(
            "metrics_{}.json",
            chrono::Utc::now().format("%Y%m%d_%H%M%S")
        ));
        
        tokio::fs::create_dir_all(output_dir).await?;
        tokio::fs::write(path, serde_json::to_string_pretty(&json)?).await?;
        
        Ok(())
    }

    /// Reports metrics in Prometheus format
    async fn report_prometheus(registry: &MetricsRegistry, output_dir: impl AsRef<Path>) -> Result<()> {
        let output_dir = output_dir.as_ref();
        let mut output = String::new();
        
        // Format runtime metrics
        output.push_str(&format!("# Runtime Metrics\n"));
        output.push_str(&format!(
            "runtime_tasks_created {}\n",
            registry.runtime.tasks_created.get()
        ));
        
        // Write to file
        let path = output_dir.join(format!(
            "metrics_{}.prom",
            chrono::Utc::now().format("%Y%m%d_%H%M%S")
        ));
        
        tokio::fs::create_dir_all(output_dir).await?;
        tokio::fs::write(path, output).await?;
        
        Ok(())
    }

    /// Reports metrics in OpenTelemetry format
    async fn report_opentelemetry(registry: &MetricsRegistry) -> Result<()> {
        // OpenTelemetry implementation would go here
        Ok(())
    }
}

// ===== Level 4: Report Orchestration =====
// Design Choice: Using metrics for self-monitoring

/// Reporter metrics
#[derive(Debug, Clone)]
struct ReporterMetrics {
    reports: Counter,
    report_errors: Counter,
    report_duration: Histogram,
}

impl ReporterMetrics {
    fn new() -> Self {
        Self {
            reports: Counter::new(),
            report_errors: Counter::new(),
            report_duration: Histogram::new(),
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::TempDir;

    #[tokio::test]
    async fn test_metrics_reporter() {
        let temp_dir = TempDir::new().unwrap();
        let registry = Arc::new(RwLock::new(MetricsRegistry::new()));
        
        let config = MetricsConfig {
            enabled: true,
            interval: Duration::from_secs(1),
            format: MetricsFormat::Json,
            output_dir: temp_dir.path().to_path_buf(),
        };

        let reporter = MetricsReporter::new(registry, config);
        
        assert!(reporter.start().await.is_ok());
        
        // Wait for some reports
        tokio::time::sleep(Duration::from_secs(2)).await;
        
        assert!(reporter.stop().await.is_ok());
        
        // Check if files were created
        let files = std::fs::read_dir(temp_dir.path()).unwrap();
        assert!(files.count() > 0);
    }
}
-e 

=== /home/amuldotexe/Desktop/GitHub202410/parseltongue/phase01/src/metrics/mod.rs ===
//! Metrics Infrastructure
//! 
//! Pyramid Structure:
//! 
//! Level 4 (Top): Metrics Orchestration
//! - MetricsManager    (coordinates all metrics)
//! - MetricsRegistry   (global metrics store)
//! - MetricsExporter   (exports metrics)
//! 
//! Level 3: Metrics Types
//! - RuntimeMetrics    (runtime stats)
//! - StorageMetrics    (storage stats)
//! - ProcessingMetrics (processing stats)
//! 
//! Level 2: Metrics Implementation
//! - MetricsCollector  (collects metrics)
//! - MetricsReporter   (reports metrics)
//! - MetricsFormatter  (formats metrics)
//! 
//! Level 1 (Base): Core Metrics Types
//! - MetricsConfig    (metrics config)
//! - MetricsValue     (value types)
//! - MetricsError     (metrics errors)

pub mod collect;
pub mod report;

use std::sync::Arc;
use tokio::sync::RwLock;
use metrics::{Counter, Gauge, Histogram};
use crate::core::error::Result;
use std::path::PathBuf;
use std::path::Path;
use chrono::Utc;
use serde_json;

// ===== Level 1: Core Metrics Types =====
// Design Choice: Using metrics crate for standardization

/// Metrics configuration
#[derive(Debug, Clone)]
pub struct MetricsConfig {
    /// Enable metrics collection
    pub enabled: bool,
    /// Collection interval
    pub interval: std::time::Duration,
    /// Export format
    pub format: MetricsFormat,
    /// Output directory (owned PathBuf needed for config)
    pub output_dir: PathBuf,
}

/// Metrics format options
#[derive(Debug, Clone, Copy)]
pub enum MetricsFormat {
    Json,
    Prometheus,
    OpenTelemetry,
}

impl Default for MetricsConfig {
    fn default() -> Self {
        Self {
            enabled: true,
            interval: std::time::Duration::from_secs(1),
            format: MetricsFormat::Json,
            output_dir: std::path::PathBuf::from("metrics"),
        }
    }
}

// ===== Level 2: Metrics Implementation =====
// Design Choice: Using RwLock for thread-safe metrics

/// Metrics manager implementation
pub struct MetricsManager {
    /// Metrics configuration
    config: MetricsConfig,
    /// Metrics registry
    registry: Arc<RwLock<MetricsRegistry>>,
    /// Metrics collector
    collector: Arc<collect::MetricsCollector>,
    /// Metrics reporter
    reporter: Arc<report::MetricsReporter>,
}

impl MetricsManager {
    /// Creates new metrics manager
    pub fn new(config: MetricsConfig) -> Self {
        let registry = Arc::new(RwLock::new(MetricsRegistry::new()));
        let collector = Arc::new(collect::MetricsCollector::new(registry.clone()));
        let reporter = Arc::new(report::MetricsReporter::new(registry.clone(), config.clone()));

        Self {
            config,
            registry,
            collector,
            reporter,
        }
    }

    /// Starts metrics collection and reporting
    pub async fn start(&self) -> Result<()> {
        if self.config.enabled {
            self.collector.start().await?;
            self.reporter.start().await?;
        }
        Ok(())
    }

    /// Stops metrics collection and reporting
    pub async fn stop(&self) -> Result<()> {
        if self.config.enabled {
            self.collector.stop().await?;
            self.reporter.stop().await?;
        }
        Ok(())
    }

    /// Records a counter metric
    pub async fn record_counter(&self, name: &str, value: u64) -> Result<()> {
        if self.config.enabled {
            let mut registry = self.registry.write().await;
            registry.record_counter(name, value);
        }
        Ok(())
    }

    /// Records a gauge metric
    pub async fn record_gauge(&self, name: &str, value: f64) -> Result<()> {
        if self.config.enabled {
            let mut registry = self.registry.write().await;
            registry.record_gauge(name, value);
        }
        Ok(())
    }

    /// Records a histogram metric
    pub async fn record_histogram(&self, name: &str, value: f64) -> Result<()> {
        if self.config.enabled {
            let mut registry = self.registry.write().await;
            registry.record_histogram(name, value);
        }
        Ok(())
    }

    /// Writes metrics to path
    pub async fn write_metrics(&self, path: impl AsRef<Path>) -> Result<()> {
        if !self.config.enabled {
            return Ok(());
        }

        let path = path.as_ref();
        let registry = self.registry.read().await;

        match self.config.format {
            MetricsFormat::Json => {
                let json = serde_json::to_value(&*registry)?;
                tokio::fs::write(path, serde_json::to_string_pretty(&json)?).await?;
            }
            MetricsFormat::Prometheus => {
                let output = self.format_prometheus(&registry)?;
                tokio::fs::write(path, output).await?;
            }
            MetricsFormat::OpenTelemetry => {
                // OpenTelemetry implementation
            }
        }

        Ok(())
    }

    /// Gets metrics file path
    fn get_metrics_path(&self) -> PathBuf {
        self.config.output_dir.join(format!(
            "metrics_{}.{}",
            Utc::now().format("%Y%m%d_%H%M%S"),
            match self.config.format {
                MetricsFormat::Json => "json",
                MetricsFormat::Prometheus => "prom",
                MetricsFormat::OpenTelemetry => "otlp",
            }
        ))
    }
}

// ===== Level 3: Metrics Types =====
// Design Choice: Using separate metric groups

/// Metrics registry implementation
#[derive(Debug)]
pub struct MetricsRegistry {
    /// Runtime metrics
    runtime: RuntimeMetrics,
    /// Storage metrics
    storage: StorageMetrics,
    /// Processing metrics
    processing: ProcessingMetrics,
}

impl MetricsRegistry {
    fn new() -> Self {
        Self {
            runtime: RuntimeMetrics::new(),
            storage: StorageMetrics::new(),
            processing: ProcessingMetrics::new(),
        }
    }

    fn record_counter(&mut self, name: &str, value: u64) {
        match name {
            s if s.starts_with("runtime") => self.runtime.record_counter(s, value),
            s if s.starts_with("storage") => self.storage.record_counter(s, value),
            s if s.starts_with("processing") => self.processing.record_counter(s, value),
            _ => {}
        }
    }

    fn record_gauge(&mut self, name: &str, value: f64) {
        match name {
            s if s.starts_with("runtime") => self.runtime.record_gauge(s, value),
            s if s.starts_with("storage") => self.storage.record_gauge(s, value),
            s if s.starts_with("processing") => self.processing.record_gauge(s, value),
            _ => {}
        }
    }

    fn record_histogram(&mut self, name: &str, value: f64) {
        match name {
            s if s.starts_with("runtime") => self.runtime.record_histogram(s, value),
            s if s.starts_with("storage") => self.storage.record_histogram(s, value),
            s if s.starts_with("processing") => self.processing.record_histogram(s, value),
            _ => {}
        }
    }
}

// ===== Level 4: Metrics Orchestration =====
// Design Choice: Using separate metric groups

/// Runtime metrics collection
#[derive(Debug)]
pub struct RuntimeMetrics {
    pub tasks_created: Counter,
    pub tasks_completed: Counter,
    pub active_tasks: Gauge,
    pub task_duration: Histogram,
}

impl RuntimeMetrics {
    fn new() -> Self {
        Self {
            tasks_created: Counter::new(),
            tasks_completed: Counter::new(),
            active_tasks: Gauge::new(),
            task_duration: Histogram::new(),
        }
    }

    fn record_counter(&mut self, name: &str, value: u64) {
        match name {
            "runtime.tasks_created" => self.tasks_created.increment(value),
            "runtime.tasks_completed" => self.tasks_completed.increment(value),
            _ => {}
        }
    }

    fn record_gauge(&mut self, name: &str, value: f64) {
        if name == "runtime.active_tasks" {
            self.active_tasks.set(value);
        }
    }

    fn record_histogram(&mut self, name: &str, value: f64) {
        if name == "runtime.task_duration" {
            self.task_duration.record(value);
        }
    }
}

/// Storage metrics collection
#[derive(Debug)]
pub struct StorageMetrics {
    pub bytes_written: Counter,
    pub bytes_read: Counter,
    pub active_connections: Gauge,
    pub operation_duration: Histogram,
}

impl StorageMetrics {
    fn new() -> Self {
        Self {
            bytes_written: Counter::new(),
            bytes_read: Counter::new(),
            active_connections: Gauge::new(),
            operation_duration: Histogram::new(),
        }
    }

    fn record_counter(&mut self, name: &str, value: u64) {
        match name {
            "storage.bytes_written" => self.bytes_written.increment(value),
            "storage.bytes_read" => self.bytes_read.increment(value),
            _ => {}
        }
    }

    fn record_gauge(&mut self, name: &str, value: f64) {
        if name == "storage.active_connections" {
            self.active_connections.set(value);
        }
    }

    fn record_histogram(&mut self, name: &str, value: f64) {
        if name == "storage.operation_duration" {
            self.operation_duration.record(value);
        }
    }
}

/// Processing metrics collection
#[derive(Debug)]
pub struct ProcessingMetrics {
    pub entries_processed: Counter,
    pub bytes_processed: Counter,
    pub active_processors: Gauge,
    pub processing_duration: Histogram,
}

impl ProcessingMetrics {
    fn new() -> Self {
        Self {
            entries_processed: Counter::new(),
            bytes_processed: Counter::new(),
            active_processors: Gauge::new(),
            processing_duration: Histogram::new(),
        }
    }

    fn record_counter(&mut self, name: &str, value: u64) {
        match name {
            "processing.entries_processed" => self.entries_processed.increment(value),
            "processing.bytes_processed" => self.bytes_processed.increment(value),
            _ => {}
        }
    }

    fn record_gauge(&mut self, name: &str, value: f64) {
        if name == "processing.active_processors" {
            self.active_processors.set(value);
        }
    }

    fn record_histogram(&mut self, name: &str, value: f64) {
        if name == "processing.processing_duration" {
            self.processing_duration.record(value);
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::time::Duration;
    use tempfile::TempDir;

    #[tokio::test]
    async fn test_metrics_manager() {
        let temp_dir = TempDir::new().unwrap();
        
        let config = MetricsConfig {
            enabled: true,
            interval: Duration::from_secs(1),
            format: MetricsFormat::Json,
            output_dir: temp_dir.path().to_path_buf(),
        };

        let manager = MetricsManager::new(config);
        
        assert!(manager.start().await.is_ok());
        
        // Test recording metrics
        manager.record_counter("runtime.tasks_created", 1).await.unwrap();
        manager.record_gauge("storage.active_connections", 2.0).await.unwrap();
        manager.record_histogram("processing.processing_duration", 100.0).await.unwrap();
        
        assert!(manager.stop().await.is_ok());
    }
}
-e 

=== /home/amuldotexe/Desktop/GitHub202410/parseltongue/phase01/src/metrics/collect.rs ===
//! Metrics Collection Implementation
//! 
//! Pyramid Structure:
//! 
//! Level 4 (Top): Collection Orchestration
//! - CollectionManager (manages collection)
//! - CollectionMetrics (tracks collection)
//! - CollectionTasks   (collection tasks)
//! 
//! Level 3: Collection Types
//! - SystemCollector   (system metrics)
//! - RuntimeCollector  (runtime metrics)
//! - CustomCollector   (custom metrics)
//! 
//! Level 2: Collection Implementation
//! - AsyncCollector    (async collection)
//! - CollectionState   (collection state)
//! - MetricsBuffer     (metrics buffer)
//! 
//! Level 1 (Base): Core Collection Types
//! - CollectorConfig   (collector config)
//! - CollectionResult  (result types)
//! - CollectionError   (collection errors)

use std::sync::Arc;
use tokio::sync::RwLock;
use tokio::time::{Duration, interval};
use metrics::{Counter, Gauge, Histogram};
use crate::core::error::Result;
use super::{MetricsRegistry, MetricsConfig};

// ===== Level 1: Core Collection Types =====
// Design Choice: Using async collection for efficiency

/// Collector configuration
#[derive(Debug, Clone)]
pub struct CollectorConfig {
    /// Collection interval
    pub interval: Duration,
    /// Buffer size
    pub buffer_size: usize,
    /// Enable system metrics
    pub system_metrics: bool,
}

impl Default for CollectorConfig {
    fn default() -> Self {
        Self {
            interval: Duration::from_secs(1),
            buffer_size: 1000,
            system_metrics: true,
        }
    }
}

// ===== Level 2: Collection Implementation =====
// Design Choice: Using interval-based collection

/// Metrics collector implementation
pub struct MetricsCollector {
    /// Metrics registry
    registry: Arc<RwLock<MetricsRegistry>>,
    /// Collection task handle
    task: RwLock<Option<tokio::task::JoinHandle<()>>>,
    /// Collector metrics
    metrics: CollectorMetrics,
    /// Collector configuration
    config: CollectorConfig,
}

impl MetricsCollector {
    /// Creates new metrics collector
    pub fn new(registry: Arc<RwLock<MetricsRegistry>>) -> Self {
        Self {
            registry,
            task: RwLock::new(None),
            metrics: CollectorMetrics::new(),
            config: CollectorConfig::default(),
        }
    }

    /// Starts metrics collection
    pub async fn start(&self) -> Result<()> {
        let mut task = self.task.write().await;
        if task.is_some() {
            return Ok(());
        }

        let registry = self.registry.clone();
        let metrics = self.metrics.clone();
        let config = self.config.clone();

        *task = Some(tokio::spawn(async move {
            let mut interval = interval(config.interval);
            
            loop {
                interval.tick().await;
                metrics.collections.increment(1);
                
                if let Err(e) = Self::collect_metrics(&registry).await {
                    metrics.collection_errors.increment(1);
                    tracing::error!("Metrics collection error: {}", e);
                }
            }
        }));

        Ok(())
    }

    /// Stops metrics collection
    pub async fn stop(&self) -> Result<()> {
        let mut task = self.task.write().await;
        if let Some(handle) = task.take() {
            handle.abort();
        }
        Ok(())
    }

    // ===== Level 3: Collection Types =====
    // Design Choice: Using separate collectors for different metrics

    /// Collects all metrics
    async fn collect_metrics(registry: &Arc<RwLock<MetricsRegistry>>) -> Result<()> {
        let mut registry = registry.write().await;
        
        // Collect system metrics
        Self::collect_system_metrics(&mut registry)?;
        
        // Collect runtime metrics
        Self::collect_runtime_metrics(&mut registry)?;
        
        // Collect custom metrics
        Self::collect_custom_metrics(&mut registry)?;
        
        Ok(())
    }

    /// Collects system metrics
    fn collect_system_metrics(registry: &mut MetricsRegistry) -> Result<()> {
        let sys_info = sys_info::System::new();
        
        // CPU usage
        if let Ok(cpu) = sys_info.cpu_load_aggregate() {
            registry.record_gauge("system.cpu_usage", cpu.user * 100.0);
        }

        // Memory usage
        if let Ok(mem) = sys_info.memory() {
            let used_mem = (mem.total - mem.free) as f64;
            registry.record_gauge("system.memory_usage", used_mem);
        }

        Ok(())
    }

    /// Collects runtime metrics
    fn collect_runtime_metrics(registry: &mut MetricsRegistry) -> Result<()> {
        // Thread count
        registry.record_gauge("runtime.thread_count", 
            std::thread::available_parallelism()?.get() as f64);

        Ok(())
    }

    /// Collects custom metrics
    fn collect_custom_metrics(registry: &mut MetricsRegistry) -> Result<()> {
        // Custom metrics collection
        Ok(())
    }
}

// ===== Level 4: Collection Orchestration =====
// Design Choice: Using metrics for self-monitoring

/// Collector metrics
#[derive(Debug, Clone)]
struct CollectorMetrics {
    collections: Counter,
    collection_errors: Counter,
    collection_duration: Histogram,
}

impl CollectorMetrics {
    fn new() -> Self {
        Self {
            collections: Counter::new(),
            collection_errors: Counter::new(),
            collection_duration: Histogram::new(),
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_metrics_collector() {
        let registry = Arc::new(RwLock::new(MetricsRegistry::new()));
        let collector = MetricsCollector::new(registry);
        
        assert!(collector.start().await.is_ok());
        
        // Wait for some collections
        tokio::time::sleep(Duration::from_secs(2)).await;
        
        assert!(collector.stop().await.is_ok());
    }
}
-e 

=== /home/amuldotexe/Desktop/GitHub202410/parseltongue/phase01/src/zip/validation.rs ===
//! ZIP Entry Validation
//! 
//! Pyramid Structure:
//! 
//! Level 4 (Top): Validation Orchestration
//! - ValidationManager (manages validation)
//! - ValidationMetrics (tracks validation)
//! - ResultAggregator  (combines results)
//! 
//! Level 3: Validation Types
//! - CrcValidator     (validates CRC32)
//! - PathValidator    (validates paths)
//! - SizeValidator    (validates sizes)
//! 
//! Level 2: Validation Implementation
//! - AsyncValidator   (async validation)
//! - ValidationState  (validation state)
//! - ResultCollector  (result collection)
//! 
//! Level 1 (Base): Core Validation Types
//! - ValidationConfig (validation config)
//! - ValidationResult (result types)
//! - ValidationError  (validation errors)

use std::sync::Arc;
use tokio::sync::Semaphore;
use crc32fast::Hasher;
use metrics::{Counter, Gauge};
use crate::core::{error::{Error, Result}, types::*};
use super::ZipEntry;

// ===== Level 1: Core Validation Types =====
// Design Choice: Using type-state pattern for validation states

/// Validation metrics collection
#[derive(Debug, Default)]
struct ValidationMetrics {
    validations_completed: Counter,
    validation_errors: Counter,
    active_validations: Gauge,
}

impl ValidationMetrics {
    fn new() -> Self {
        Self::default()
    }
}

/// Validation configuration
#[derive(Debug, Clone)]
pub struct ValidationConfig {
    /// Enable CRC validation
    pub validate_crc: bool,
    /// Enable path validation
    pub validate_paths: bool,
    /// Maximum path length
    pub max_path_length: usize,
    /// Maximum concurrent validations
    pub max_concurrent: usize,
}

impl Default for ValidationConfig {
    fn default() -> Self {
        Self {
            validate_crc: true,
            validate_paths: true,
            max_path_length: 256,
            max_concurrent: 4,
        }
    }
}

// ===== Level 2: Validation Implementation =====
// Design Choice: Using async traits for concurrent validation

/// Entry validator implementation
pub struct EntryValidator {
    /// Validation configuration
    config: ValidationConfig,
    /// Validation semaphore
    semaphore: Arc<Semaphore>,
    /// Validation metrics
    metrics: ValidationMetrics,
}

impl EntryValidator {
    /// Creates new entry validator
    pub fn new(config: ValidationConfig) -> Self {
        let semaphore = Arc::new(Semaphore::new(config.max_concurrent));
        let metrics = ValidationMetrics::new();

        Self {
            config,
            semaphore,
            metrics,
        }
    }

    // ===== Level 3: Validation Types =====
    // Design Choice: Using separate validation functions for modularity

    /// Validates ZIP entry
    pub async fn validate(&self, entry: &ZipEntry) -> Result<()> {
        let _permit = self.semaphore.acquire().await?;
        self.metrics.active_validations.increment(1.0);

        let result = async {
            // Validate path
            if self.config.validate_paths {
                self.validate_path(entry)?;
            }

            // Validate CRC
            if self.config.validate_crc {
                self.validate_crc(entry)?;
            }

            Ok(())
        }.await;

        self.metrics.active_validations.decrement(1.0);
        
        match result {
            Ok(_) => {
                self.metrics.validations_completed.increment(1);
                Ok(())
            }
            Err(e) => {
                self.metrics.validation_errors.increment(1);
                Err(e)
            }
        }
    }

    /// Validates entry path
    fn validate_path(&self, entry: &ZipEntry) -> Result<()> {
        let path_str = entry.path.to_string_lossy();
        
        // Check path length
        if path_str.len() > self.config.max_path_length {
            return Err(Error::InvalidPath(entry.path.clone()));
        }

        // Check for path traversal
        if path_str.contains("..") {
            return Err(Error::InvalidPath(entry.path.clone()));
        }

        // Check for absolute paths
        if entry.path.is_absolute() {
            return Err(Error::InvalidPath(entry.path.clone()));
        }

        Ok(())
    }

    /// Validates entry CRC
    fn validate_crc(&self, entry: &ZipEntry) -> Result<()> {
        let mut hasher = Hasher::new();
        hasher.update(&entry.data);
        let computed_crc = hasher.finalize();

        if computed_crc != entry.crc32 {
            return Err(Error::ValidationFailed(format!(
                "CRC mismatch for {}: expected {:x}, got {:x}",
                entry.path.display(),
                entry.crc32,
                computed_crc
            )));
        }

        Ok(())
    }
}

// ===== Level 4: Validation Orchestration =====
// Design Choice: Using builder pattern for validation chain

/// Validation chain builder
pub struct ValidationChain {
    validators: Vec<Box<dyn Fn(&ZipEntry) -> Result<()> + Send + Sync>>,
}

impl ValidationChain {
    pub fn new() -> Self {
        Self {
            validators: Vec::new(),
        }
    }

    pub fn add_validator<F>(&mut self, validator: F) -> &mut Self 
    where
        F: Fn(&ZipEntry) -> Result<()> + Send + Sync + 'static,
    {
        self.validators.push(Box::new(validator));
        self
    }

    pub fn validate(&self, entry: &ZipEntry) -> Result<()> {
        for validator in &self.validators {
            validator(entry)?;
        }
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::path::PathBuf;
    use bytes::Bytes;

    #[tokio::test]
    async fn test_path_validation() {
        let config = ValidationConfig {
            validate_paths: true,
            max_path_length: 10,
            ..Default::default()
        };

        let validator = EntryValidator::new(config);

        // Test valid path
        let entry = ZipEntry {
            path: PathBuf::from("test.txt"),
            data: Bytes::from("test"),
            crc32: 0xd87f7e0c,  // CRC32 of "test"
            size: 4,
        };

        assert!(validator.validate(&entry).await.is_ok());

        // Test invalid path
        let entry = ZipEntry {
            path: PathBuf::from("../test.txt"),
            data: Bytes::new(),
            crc32: 0,
            size: 0,
        };

        assert!(validator.validate(&entry).await.is_err());
    }

    #[tokio::test]
    async fn test_crc_validation() {
        let config = ValidationConfig {
            validate_crc: true,
            ..Default::default()
        };

        let validator = EntryValidator::new(config);

        let entry = ZipEntry {
            path: PathBuf::from("test.txt"),
            data: Bytes::from("test"),
            crc32: 0xd87f7e0c,  // Correct CRC32 for "test"
            size: 4,
        };

        assert!(validator.validate(&entry).await.is_ok());

        let entry = ZipEntry {
            path: PathBuf::from("test.txt"),
            data: Bytes::from("test"),
            crc32: 0x12345678,  // Incorrect CRC32
            size: 4,
        };

        assert!(validator.validate(&entry).await.is_err());
    }
}
-e 

=== /home/amuldotexe/Desktop/GitHub202410/parseltongue/phase01/src/zip/reader.rs ===
//! ZIP File Reading Implementation
//! 
//! Pyramid Structure:
//! 
//! Level 4 (Top): Stream Processing
//! - StreamProcessor   (processes ZIP stream)
//! - StreamMetrics     (tracks stream metrics)
//! - BufferManager     (manages read buffers)
//! 
//! Level 3: Entry Processing
//! - EntryReader      (reads ZIP entries)
//! - EntryStream      (streams entry data)
//! - DataProcessor    (processes entry data)
//! 
//! Level 2: Reading Implementation
//! - AsyncReader      (async reading logic)
//! - ReadBuffer       (buffer management)
//! - ChunkProcessor   (chunk processing)
//! 
//! Level 1 (Base): Core Reading Types
//! - ReaderConfig     (reader configuration)
//! - ReadBuffer       (buffer types)
//! - ReadError        (reading errors)

use std::sync::Arc;
use tokio::io::{AsyncRead, AsyncReadExt, AsyncSeek, AsyncSeekExt};
use bytes::{Bytes, BytesMut};
use futures::{Stream, StreamExt};
use zip::{ZipArchive, result::ZipError};
use crate::core::{error::{Error, Result}, types::*};
use super::{ZipEntry, ZipConfig};

// ===== Level 1: Core Reading Types =====
// Design Choice: Using BytesMut for efficient buffering

/// Reader metrics collection
#[derive(Debug, Default)]
struct ReaderMetrics {
    bytes_read: Counter,
    entries_processed: Counter,
    buffer_resizes: Counter,
}

impl ReaderMetrics {
    fn new() -> Self {
        Self::default()
    }
}

/// Async ZIP reader implementation
pub struct AsyncZipReader<R> {
    /// Inner reader
    reader: R,
    /// Reader configuration
    config: ZipConfig,
    /// Read buffer
    buffer: BytesMut,
    /// Current position
    position: u64,
    /// Reader metrics
    metrics: ReaderMetrics,
}

// ===== Level 2: Reading Implementation =====
// Design Choice: Using async/await for non-blocking I/O

impl<R: AsyncRead + AsyncSeek + Unpin + Send + 'static> AsyncZipReader<R> {
    /// Creates new async ZIP reader
    pub fn new(reader: R, config: ZipConfig) -> Self {
        let buffer = BytesMut::with_capacity(config.buffer_size);
        let metrics = ReaderMetrics::new();

        Self {
            reader,
            config,
            buffer,
            position: 0,
            metrics,
        }
    }

    /// Reads next ZIP entry
    pub async fn next_entry(&mut self) -> Result<Option<ZipEntry>> {
        // Read ZIP header
        let header = self.read_entry_header().await?;
        
        if header.is_none() {
            return Ok(None);
        }
        let header = header.unwrap();

        // Read entry data
        let data = self.read_entry_data(&header).await?;
        
        // Create ZIP entry
        let entry = ZipEntry {
            path: header.name().into(),
            data: data.into(),
            crc32: header.crc32(),
            size: header.size(),
        };

        self.metrics.entries_processed.increment(1);
        Ok(Some(entry))
    }

    // ===== Level 3: Entry Processing =====
    // Design Choice: Using async helpers for modularity

    /// Reads entry header
    async fn read_entry_header(&mut self) -> Result<Option<zip::read::ZipFile>> {
        // Ensure buffer has enough space
        if self.buffer.len() < self.config.buffer_size {
            self.buffer.reserve(self.config.buffer_size);
            self.metrics.buffer_resizes.increment(1);
        }

        // Read header bytes
        let bytes_read = self.reader.read_buf(&mut self.buffer).await?;
        if bytes_read == 0 {
            return Ok(None);
        }

        self.metrics.bytes_read.increment(bytes_read as u64);
        self.position += bytes_read as u64;

        // Parse header
        let mut archive = ZipArchive::new(std::io::Cursor::new(&self.buffer))?;
        Ok(archive.by_index(0).ok())
    }

    /// Reads entry data
    async fn read_entry_data(&mut self, entry: &zip::read::ZipFile) -> Result<Bytes> {
        let mut data = Vec::with_capacity(entry.size() as usize);
        
        // Read compressed data
        let mut remaining = entry.compressed_size();
        while remaining > 0 {
            let bytes_read = self.reader.read_buf(&mut self.buffer).await?;
            if bytes_read == 0 {
                break;
            }

            data.extend_from_slice(&self.buffer[..bytes_read]);
            remaining = remaining.saturating_sub(bytes_read as u64);
            
            self.metrics.bytes_read.increment(bytes_read as u64);
            self.position += bytes_read as u64;
        }

        // Decompress if needed
        if entry.compression() != zip::CompressionMethod::Stored {
            // Use zip crate's decompression
            let decompressed = entry.decompress()?;
            Ok(Bytes::from(decompressed))
        } else {
            Ok(Bytes::from(data))
        }
    }
}

// ===== Level 4: Stream Processing =====
// Design Choice: Using Stream trait for composability

impl<R: AsyncRead + AsyncSeek + Unpin + Send + 'static> Stream for AsyncZipReader<R> {
    type Item = Result<ZipEntry>;

    fn poll_next(
        mut self: std::pin::Pin<&mut Self>,
        cx: &mut std::task::Context<'_>,
    ) -> std::task::Poll<Option<Self::Item>> {
        use std::task::Poll;
        
        let future = self.next_entry();
        futures::pin_mut!(future);
        
        future.poll(cx)
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::io::Cursor;

    #[tokio::test]
    async fn test_reader_basic() {
        // Create test ZIP data
        let mut data = Vec::new();
        {
            let mut zip = zip::ZipWriter::new(Cursor::new(&mut data));
            zip.start_file("test.txt", Default::default()).unwrap();
            zip.write_all(b"Hello, World!").unwrap();
            zip.finish().unwrap();
        }

        let cursor = Cursor::new(data);
        let config = ZipConfig {
            buffer_size: 8192,
            max_concurrent_entries: 4,
            validation_config: ValidationConfig::default(),
            encoding_config: EncodingConfig::default(),
        };

        let mut reader = AsyncZipReader::new(cursor, config);
        
        // Test reading entry
        let entry = reader.next_entry().await.unwrap().unwrap();
        assert_eq!(entry.path.to_str().unwrap(), "test.txt");
        assert_eq!(&entry.data[..], b"Hello, World!");
    }
}
-e 

=== /home/amuldotexe/Desktop/GitHub202410/parseltongue/phase01/src/zip/encoding.rs ===
//! ZIP Entry Encoding Management
//! 
//! Pyramid Structure:
//! 
//! Level 4 (Top): Encoding Management
//! - EncodingManager   (manages encodings)
//! - EncodingMetrics   (tracks encoding usage)
//! - FallbackManager   (manages fallbacks)
//! 
//! Level 3: Encoding Operations
//! - EncodingDetector  (detects encodings)
//! - EncodingConverter (converts encodings)
//! - FallbackHandler   (handles failures)
//! 
//! Level 2: Encoding Implementation
//! - AsyncEncoder      (async encoding)
//! - EncodingState     (encoding state)
//! - ConversionBuffer  (conversion buffer)
//! 
//! Level 1 (Base): Core Encoding Types
//! - EncodingConfig    (encoding config)
//! - EncodingResult    (result types)
//! - EncodingError     (encoding errors)

use std::sync::Arc;
use encoding_rs::{Encoding, UTF_8, WINDOWS_1252, CoderResult};
use chardetng::EncodingDetector as ChardetDetector;
use metrics::{Counter, Gauge};
use crate::core::{error::{Error, Result}, types::*};

// ===== Level 1: Core Encoding Types =====
// Design Choice: Using encoding_rs for reliable conversion

/// Encoding metrics collection
#[derive(Debug, Default)]
struct EncodingMetrics {
    successful_conversions: Counter,
    conversion_errors: Counter,
    fallbacks_used: Counter,
    active_conversions: Gauge,
}

impl EncodingMetrics {
    fn new() -> Self {
        Self::default()
    }
}

/// Encoding configuration
#[derive(Debug, Clone)]
pub struct EncodingConfig {
    /// Default encoding
    pub default_encoding: &'static Encoding,
    /// Fallback encoding
    pub fallback_encoding: &'static Encoding,
    /// Enable detection
    pub enable_detection: bool,
    /// Detection confidence threshold
    pub detection_threshold: f32,
}

impl Default for EncodingConfig {
    fn default() -> Self {
        Self {
            default_encoding: UTF_8,
            fallback_encoding: WINDOWS_1252,
            enable_detection: true,
            detection_threshold: 0.8,
        }
    }
}

// ===== Level 2: Encoding Implementation =====
// Design Choice: Using detection with fallback

/// Encoding detector implementation
pub struct EncodingDetector {
    /// Encoding configuration
    config: EncodingConfig,
    /// Encoding metrics
    metrics: EncodingMetrics,
}

impl EncodingDetector {
    /// Creates new encoding detector
    pub fn new(config: EncodingConfig) -> Self {
        let metrics = EncodingMetrics::new();

        Self {
            config,
            metrics,
        }
    }

    // ===== Level 3: Encoding Operations =====
    // Design Choice: Using separate functions for detection and conversion

    /// Detects and converts encoding
    pub fn detect_and_convert(&self, input: &[u8]) -> Result<String> {
        self.metrics.active_conversions.increment(1.0);

        let result = if self.config.enable_detection {
            // Try to detect encoding
            if let Some(encoding) = self.detect_encoding(input) {
                self.convert_with_encoding(input, encoding)
            } else {
                // Try default encoding
                self.convert_with_encoding(input, self.config.default_encoding)
            }
        } else {
            // Use default encoding directly
            self.convert_with_encoding(input, self.config.default_encoding)
        };

        self.metrics.active_conversions.decrement(1.0);
        result
    }

    /// Detects encoding from input
    fn detect_encoding(&self, input: &[u8]) -> Option<&'static Encoding> {
        let mut detector = ChardetDetector::new();
        detector.feed(input, true);
        
        let encoding = detector.guess(None, true);
        let confidence = detector.confidence();
        
        if confidence >= self.config.detection_threshold {
            Some(encoding)
        } else {
            None
        }
    }

    /// Converts input with specified encoding
    fn convert_with_encoding(&self, input: &[u8], encoding: &'static Encoding) -> Result<String> {
        let (cow, _encoding_used, had_errors) = encoding.decode(input);
        
        if had_errors {
            // Try fallback encoding if primary fails
            let (fallback_cow, _, fallback_errors) = self.config.fallback_encoding.decode(input);
            
            if fallback_errors {
                self.metrics.conversion_errors.increment(1);
                Err(Error::EncodingFailed("Both primary and fallback encoding failed".into()))
            } else {
                self.metrics.fallbacks_used.increment(1);
                Ok(fallback_cow.into_owned())
            }
        } else {
            self.metrics.successful_conversions.increment(1);
            Ok(cow.into_owned())
        }
    }
}

// ===== Level 4: Encoding Management =====
// Design Choice: Using builder pattern for encoding chain

/// Encoding chain builder
pub struct EncodingChain {
    encodings: Vec<&'static Encoding>,
    threshold: f32,
}

impl EncodingChain {
    pub fn new() -> Self {
        Self {
            encodings: Vec::new(),
            threshold: 0.8,
        }
    }

    pub fn add_encoding(&mut self, encoding: &'static Encoding) -> &mut Self {
        self.encodings.push(encoding);
        self
    }

    pub fn with_threshold(&mut self, threshold: f32) -> &mut Self {
        self.threshold = threshold;
        self
    }

    pub fn convert(&self, input: &[u8]) -> Result<String> {
        for encoding in &self.encodings {
            let (cow, _, had_errors) = encoding.decode(input);
            if !had_errors {
                return Ok(cow.into_owned());
            }
        }
        
        Err(Error::EncodingFailed("All encodings failed".into()))
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_utf8_conversion() {
        let config = EncodingConfig::default();
        let detector = EncodingDetector::new(config);

        let input = b"Hello, World!";
        let result = detector.detect_and_convert(input);
        
        assert!(result.is_ok());
        assert_eq!(result.unwrap(), "Hello, World!");
    }

    #[test]
    fn test_windows1252_fallback() {
        let config = EncodingConfig::default();
        let detector = EncodingDetector::new(config);

        // Windows-1252 encoded bytes
        let input = &[0x48, 0xE9, 0x6C, 0x6C, 0x6F]; // "Hllo"
        let result = detector.detect_and_convert(input);
        
        assert!(result.is_ok());
        assert_eq!(result.unwrap(), "Hllo");
    }

    #[test]
    fn test_encoding_chain() {
        let mut chain = EncodingChain::new();
        chain
            .add_encoding(UTF_8)
            .add_encoding(WINDOWS_1252);

        let input = b"Hello, World!";
        let result = chain.convert(input);
        
        assert!(result.is_ok());
        assert_eq!(result.unwrap(), "Hello, World!");
    }
}
-e 

=== /home/amuldotexe/Desktop/GitHub202410/parseltongue/phase01/src/zip/buffer.rs ===
//! ZIP Buffer Management
//! 
//! Pyramid Structure:
//! 
//! Level 4 (Top): Buffer Orchestration
//! - BufferManager    (manages buffer lifecycle)
//!    Pool management
//!    Size adaptation
//!    Memory pressure handling
//! 
//! Level 3: Memory Management
//! - MemoryTracker    (tracks memory usage)
//!    Usage monitoring
//!    Pressure detection
//!    Size adjustment
//! 
//! Level 2: Buffer Implementation
//! - AdaptiveBuffer   (smart buffering)
//!    Size scaling
//!    Chunk management
//!    Memory limits
//! 
//! Level 1 (Base): Buffer Types
//! - BufferConfig     (configuration)
//!    Size limits
//!    Growth policy
//!    Pressure thresholds

use std::sync::Arc;
use tokio::sync::Semaphore;
use bytes::{Bytes, BytesMut};
use metrics::{Counter, Gauge};
use crate::core::{error::{Error, Result}, types::*};

// ===== Level 1: Buffer Types =====
// Design Choice: Using BytesMut for zero-copy operations

/// Buffer configuration
#[derive(Debug, Clone)]
pub struct BufferConfig {
    /// Initial buffer size
    pub initial_size: usize,
    /// Maximum buffer size
    pub max_size: usize,
    /// Growth factor
    pub growth_factor: f32,
    /// Memory pressure threshold
    pub pressure_threshold: f32,
}

impl Default for BufferConfig {
    fn default() -> Self {
        Self {
            initial_size: 8 * 1024,     // 8KB initial
            max_size: 1024 * 1024,      // 1MB max
            growth_factor: 1.5,         // 50% growth
            pressure_threshold: 0.75,    // 75% memory pressure
        }
    }
}

// ===== Level 2: Buffer Implementation =====
// Design Choice: Using adaptive sizing based on pressure

/// Adaptive buffer implementation
pub struct AdaptiveBuffer {
    /// Current buffer
    buffer: BytesMut,
    /// Buffer configuration
    config: BufferConfig,
    /// Memory tracker
    tracker: Arc<MemoryTracker>,
}

impl AdaptiveBuffer {
    /// Creates new adaptive buffer
    pub fn new(config: BufferConfig) -> Self {
        let buffer = BytesMut::with_capacity(config.initial_size);
        let tracker = Arc::new(MemoryTracker::new());

        Self {
            buffer,
            config,
            tracker,
        }
    }

    /// Gets current buffer size
    pub fn size(&self) -> usize {
        self.buffer.capacity()
    }

    /// Resizes buffer based on pressure
    pub fn resize(&mut self) {
        let pressure = self.tracker.pressure();
        
        if pressure > self.config.pressure_threshold {
            // Under pressure - shrink
            let new_size = (self.size() as f32 / self.config.growth_factor) as usize;
            self.buffer.reserve(new_size.max(self.config.initial_size));
        } else {
            // Room to grow
            let new_size = (self.size() as f32 * self.config.growth_factor) as usize;
            self.buffer.reserve(new_size.min(self.config.max_size));
        }
    }
}

// ===== Level 3: Memory Management =====
// Design Choice: Using atomic metrics for thread safety

/// Memory usage tracker
pub struct MemoryTracker {
    /// Total allocated
    allocated: Gauge,
    /// Memory pressure
    pressure: Gauge,
    /// Buffer resizes
    resizes: Counter,
}

impl MemoryTracker {
    /// Creates new memory tracker
    fn new() -> Self {
        Self {
            allocated: Gauge::new(),
            pressure: Gauge::new(),
            resizes: Counter::new(),
        }
    }

    /// Gets current memory pressure
    pub fn pressure(&self) -> f32 {
        self.pressure.get()
    }

    /// Updates memory allocation
    pub fn update_allocation(&self, size: usize) {
        self.allocated.set(size as f64);
        
        // Update pressure based on system memory
        if let Ok(mem_info) = sys_info::mem_info() {
            let pressure = size as f64 / mem_info.total as f64;
            self.pressure.set(pressure);
        }
    }
}

// ===== Level 4: Buffer Orchestration =====
// Design Choice: Using pool for buffer reuse

/// Buffer pool manager
pub struct BufferManager {
    /// Buffer pool
    pool: Arc<Semaphore>,
    /// Buffer configuration
    config: BufferConfig,
    /// Memory tracker
    tracker: Arc<MemoryTracker>,
}

impl BufferManager {
    /// Creates new buffer manager
    pub fn new(config: BufferConfig, pool_size: usize) -> Self {
        Self {
            pool: Arc::new(Semaphore::new(pool_size)),
            config,
            tracker: Arc::new(MemoryTracker::new()),
        }
    }

    /// Acquires buffer from pool
    pub async fn acquire_buffer(&self) -> Result<BufferGuard> {
        let _permit = self.pool.acquire().await?;
        
        Ok(BufferGuard {
            buffer: AdaptiveBuffer::new(self.config.clone()),
            pool: self.pool.clone(),
            tracker: self.tracker.clone(),
        })
    }
}

/// RAII guard for buffer
pub struct BufferGuard {
    /// Managed buffer
    buffer: AdaptiveBuffer,
    /// Buffer pool
    pool: Arc<Semaphore>,
    /// Memory tracker
    tracker: Arc<MemoryTracker>,
}

impl BufferGuard {
    /// Gets mutable buffer reference
    pub fn get_mut(&mut self) -> &mut BytesMut {
        &mut self.buffer.buffer
    }

    /// Resizes buffer if needed
    pub fn resize(&mut self) {
        self.buffer.resize();
        self.tracker.resizes.increment(1);
        self.tracker.update_allocation(self.buffer.size());
    }
}

impl Drop for BufferGuard {
    fn drop(&mut self) {
        self.tracker.update_allocation(0);
        self.pool.add_permits(1);
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tokio::time::sleep;
    use std::time::Duration;

    #[tokio::test]
    async fn test_buffer_lifecycle() {
        let config = BufferConfig::default();
        let manager = BufferManager::new(config, 4);

        let mut guard = manager.acquire_buffer().await.unwrap();
        
        // Test initial size
        assert_eq!(guard.buffer.size(), 8 * 1024);

        // Test growth
        guard.resize();
        assert!(guard.buffer.size() > 8 * 1024);

        // Test cleanup
        drop(guard);
        
        // Pool should have permit available
        assert!(manager.acquire_buffer().await.is_ok());
    }

    #[tokio::test]
    async fn test_pressure_handling() {
        let config = BufferConfig {
            pressure_threshold: 0.5,
            ..Default::default()
        };
        
        let manager = BufferManager::new(config, 1);
        let mut guard = manager.acquire_buffer().await.unwrap();

        // Simulate memory pressure
        guard.tracker.pressure.set(0.8);
        guard.resize();

        // Buffer should shrink under pressure
        assert!(guard.buffer.size() < 8 * 1024);
    }
}
-e 

=== /home/amuldotexe/Desktop/GitHub202410/parseltongue/phase01/src/zip/mod.rs ===
//! ZIP Processing Coordination
//! 
//! Pyramid Structure:
//! 
//! Level 4 (Top): ZIP Processing Orchestration
//! - ZipProcessor     (coordinates ZIP operations)
//! - ProcessingMetrics (aggregates ZIP metrics)
//! - StreamManager    (manages ZIP streams)
//! 
//! Level 3: Processing Management
//! - EntryProcessor   (processes ZIP entries)
//! - ValidationManager (manages validation)
//! - EncodingManager  (manages encodings)
//! 
//! Level 2: ZIP Traits
//! - AsyncZipReader   (async ZIP reading)
//! - EntryValidator   (entry validation)
//! - EncodingDetector (encoding detection)
//! 
//! Level 1 (Base): Core ZIP Types
//! - ZipConfig       (ZIP configuration)
//! - ZipEntry        (entry representation)
//! - ProcessingError (ZIP-specific errors)

use std::sync::Arc;
use tokio::sync::{Semaphore, mpsc};
use bytes::Bytes;
use futures::{Stream, StreamExt};
use metrics::{Counter, Gauge};
use crate::core::{error::Result, types::*};

pub mod reader;
pub mod validation;
pub mod encoding;

// Re-export main types
pub use reader::AsyncZipReader;
pub use validation::{EntryValidator, ValidationConfig};
pub use encoding::{EncodingDetector, EncodingConfig};

// ===== Level 1: Core ZIP Types =====
// Design Choice: Using async streams for processing

/// Processing metrics collection
#[derive(Debug, Default)]
struct ProcessingMetrics {
    entries_processed: Counter,
    bytes_processed: Counter,
    active_processors: Gauge,
    error_count: Counter,
}

impl ProcessingMetrics {
    fn new() -> Self {
        Self::default()
    }
}

/// ZIP processing configuration
#[derive(Debug, Clone)]
pub struct ZipConfig {
    /// Buffer size for reading
    pub buffer_size: usize,
    /// Concurrent entry limit
    pub max_concurrent_entries: usize,
    /// Validation configuration
    pub validation_config: ValidationConfig,
    /// Encoding configuration
    pub encoding_config: EncodingConfig,
}

impl Default for ZipConfig {
    fn default() -> Self {
        Self {
            buffer_size: 8192,
            max_concurrent_entries: 4,
            validation_config: ValidationConfig::default(),
            encoding_config: EncodingConfig::default(),
        }
    }
}

/// ZIP entry representation
#[derive(Debug, Clone)]
pub struct ZipEntry {
    /// Entry path
    pub path: std::path::PathBuf,
    /// Entry data
    pub data: Bytes,
    /// Entry CRC32
    pub crc32: u32,
    /// Entry size
    pub size: u64,
}

// ===== Level 2: ZIP Traits =====
// Design Choice: Using async traits for operations

/// Async ZIP processing interface
#[async_trait::async_trait]
pub trait AsyncZipProcessor: Send + Sync + 'static {
    /// Process ZIP entry
    async fn process_entry(&self, entry: ZipEntry) -> Result<()>;
    /// Process completion
    async fn complete(&self) -> Result<()>;
}

// ===== Level 3: Processing Management =====
// Design Choice: Using channels for communication

/// ZIP processor implementation
pub struct ZipProcessor {
    /// Processing configuration
    config: ZipConfig,
    /// Entry processor
    processor: Arc<dyn AsyncZipProcessor>,
    /// Validation manager
    validator: Arc<EntryValidator>,
    /// Encoding detector
    encoding: Arc<EncodingDetector>,
    /// Processing metrics
    metrics: ProcessingMetrics,
    /// Entry channel
    entry_tx: mpsc::Sender<ZipEntry>,
}

impl ZipProcessor {
    /// Creates new ZIP processor
    pub fn new(
        config: ZipConfig,
        processor: Arc<dyn AsyncZipProcessor>,
    ) -> (Self, mpsc::Receiver<ZipEntry>) {
        let (entry_tx, entry_rx) = mpsc::channel(config.max_concurrent_entries);
        let validator = Arc::new(EntryValidator::new(config.validation_config.clone()));
        let encoding = Arc::new(EncodingDetector::new(config.encoding_config.clone()));
        let metrics = ProcessingMetrics::new();

        (Self {
            config,
            processor,
            validator,
            encoding,
            metrics,
            entry_tx,
        }, entry_rx)
    }

    // ===== Level 4: Processing Orchestration =====
    // Design Choice: Using worker tasks for processing

    /// Processes ZIP file
    pub async fn process<R>(&self, reader: R) -> Result<()>
    where
        R: AsyncRead + AsyncSeek + Unpin + Send + 'static,
    {
        let mut reader = AsyncZipReader::new(reader, self.config.clone());
        let semaphore = Arc::new(Semaphore::new(self.config.max_concurrent_entries));

        let mut tasks = Vec::new();
        
        while let Some(entry) = reader.next_entry().await? {
            let permit = semaphore.clone().acquire_owned().await?;
            let processor = self.processor.clone();
            let validator = self.validator.clone();
            let metrics = self.metrics.clone();
            
            // Spawn processing task
            let task = tokio::spawn(async move {
                metrics.active_processors.increment(1.0);
                
                let result = async {
                    // Validate entry
                    validator.validate(&entry).await?;
                    
                    // Process entry
                    processor.process_entry(entry).await?;
                    
                    Ok(())
                }.await;
                
                metrics.active_processors.decrement(1.0);
                drop(permit);
                
                result
            });
            
            tasks.push(task);
        }

        // Wait for all tasks
        for task in tasks {
            task.await??;
        }

        // Signal completion
        self.processor.complete().await?;
        
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::io::Cursor;

    struct TestProcessor;

    #[async_trait::async_trait]
    impl AsyncZipProcessor for TestProcessor {
        async fn process_entry(&self, entry: ZipEntry) -> Result<()> {
            println!("Processing: {}", entry.path.display());
            Ok(())
        }

        async fn complete(&self) -> Result<()> {
            Ok(())
        }
    }

    #[tokio::test]
    async fn test_zip_processor() {
        let config = ZipConfig::default();
        let processor = Arc::new(TestProcessor);
        
        let (zip_processor, _rx) = ZipProcessor::new(config.clone(), processor);

        // Create test ZIP
        let mut data = Vec::new();
        {
            let mut zip = zip::ZipWriter::new(Cursor::new(&mut data));
            zip.start_file("test.txt", Default::default()).unwrap();
            zip.write_all(b"Hello, World!").unwrap();
            zip.finish().unwrap();
        }

        let cursor = Cursor::new(data);
        assert!(zip_processor.process(cursor).await.is_ok());
    }
}
-e 

=== /home/amuldotexe/Desktop/GitHub202410/parseltongue/phase01/src/main.rs ===
//! Main Entry Point
//! 
//! Pyramid Structure:
//! 
//! Level 4 (Top): Application Orchestration
//! - RuntimeManager    (manages async runtime)
//! - ShutdownManager   (manages graceful shutdown)
//! - MetricsManager    (manages metrics collection)
//! 
//! Level 3: Processing Pipeline
//! - ZipProcessor     (processes ZIP files)
//! - StorageManager   (manages storage)
//! - ValidationManager (manages validation)
//! 
//! Level 2: Infrastructure Setup
//! - LoggingSetup     (configures logging)
//! - MetricsSetup     (configures metrics)
//! - StorageSetup     (configures storage)
//! 
//! Level 1 (Base): Core Setup
//! - ArgumentParser   (parses CLI args)
//! - ConfigBuilder    (builds configuration)
//! - ErrorHandler     (handles errors)

use std::path::Path;
use std::sync::Arc;
use anyhow::{Context, Result};
use clap::Parser;
use tokio::signal;
use tracing::{info, warn, error};
use tracing_subscriber::{self, EnvFilter};

use crate::{
    cli::{Args, ProgressBar},
    core::{error::Error, types::*},
    storage::{StorageManager, StorageConfig},
    zip::{ZipProcessor, ZipConfig},
    metrics::{MetricsManager, MetricsConfig},
};

// ===== Level 1: Core Setup =====
// Design Choice: Using clap for CLI argument parsing

/// Application configuration
#[derive(Debug)]
struct AppConfig {
    /// CLI arguments
    args: Args,
    /// Runtime configuration
    runtime_config: RuntimeConfig,
    /// Storage configuration
    storage_config: StorageConfig,
    /// Metrics configuration
    metrics_config: MetricsConfig,
}

impl AppConfig {
    /// Creates configuration from CLI arguments
    fn from_args(args: Args) -> Result<Self> {
        // Validate paths using AsRef<Path>
        let input_path = args.input_path.as_path();
        if !input_path.exists() {
            return Err(Error::InvalidPath(args.input_path.clone()).into());
        }

        let output_dir = args.output_dir.as_path();
        std::fs::create_dir_all(output_dir)
            .with_context(|| format!("Failed to create output directory: {}", output_dir.display()))?;

        // Create configurations
        let runtime_config = args.into_config();

        let storage_config = StorageConfig {
            path: output_dir.join("storage"),
            pool_size: args.workers,
            batch_size: 1000,
            index_config: Default::default(),
        };

        let metrics_config = MetricsConfig {
            enabled: true,
            interval: std::time::Duration::from_secs(1),
            format: Default::default(),
            output_dir: output_dir.join("metrics"),
        };

        Ok(Self {
            args,
            runtime_config,
            storage_config,
            metrics_config,
        })
    }
}

// ===== Level 2: Infrastructure Setup =====
// Design Choice: Using builder pattern for setup

/// Application state
struct App {
    /// Application configuration
    config: AppConfig,
    /// Storage manager
    storage: Arc<StorageManager>,
    /// ZIP processor
    processor: Arc<ZipProcessor>,
    /// Metrics manager
    metrics: Arc<MetricsManager>,
}

impl App {
    /// Creates new application instance
    async fn new(config: AppConfig) -> Result<Self> {
        // Initialize storage
        let storage = Arc::new(StorageManager::new(config.storage_config.clone()).await?);
        
        // Initialize processor
        let processor = Arc::new(ZipProcessor::new(
            ZipConfig::default(),
            storage.clone(),
        ));
        
        // Initialize metrics
        let metrics = Arc::new(MetricsManager::new(config.metrics_config.clone()));

        Ok(Self {
            config,
            storage,
            processor,
            metrics,
        })
    }

    /// Runs the application
    async fn run(&self) -> Result<()> {
        // Start metrics collection
        self.metrics.start().await?;

        // Create progress bar
        let progress = ProgressBar::new();
        progress.set_message("Processing ZIP file...");

        // Process ZIP file
        let file = tokio::fs::File::open(&self.config.args.input_path).await
            .with_context(|| format!("Failed to open ZIP file: {}", self.config.args.input_path.display()))?;

        self.processor.process(file).await?;

        // Cleanup
        progress.finish_with_message("Processing complete");
        self.metrics.stop().await?;

        Ok(())
    }
}

// ===== Level 3: Processing Pipeline =====
// Design Choice: Using async/await for concurrency

/// Sets up logging
fn setup_logging(verbose: bool) -> Result<()> {
    let filter = if verbose {
        EnvFilter::from_default_env().add_directive(tracing::Level::DEBUG.into())
    } else {
        EnvFilter::from_default_env().add_directive(tracing::Level::INFO.into())
    };

    tracing_subscriber::fmt()
        .with_env_filter(filter)
        .with_file(true)
        .with_line_number(true)
        .init();

    Ok(())
}

// ===== Level 4: Application Orchestration =====
// Design Choice: Using tokio for async runtime

#[tokio::main]
async fn main() -> Result<()> {
    // Parse arguments
    let args = Args::parse();

    // Setup logging
    setup_logging(args.verbose)?;

    // Create application
    let config = AppConfig::from_args(args)?;
    let app = App::new(config).await?;

    // Setup signal handlers
    let (shutdown_tx, mut shutdown_rx) = tokio::sync::broadcast::channel(1);
    let shutdown_tx = Arc::new(shutdown_tx);

    tokio::spawn({
        let tx = Arc::clone(&shutdown_tx);
        async move {
            if let Ok(()) = signal::ctrl_c().await {
                info!("Received Ctrl+C, initiating shutdown");
                let _ = tx.send(());
            }
        }
    });

    // Run application with shutdown handling
    tokio::select! {
        result = app.run() => {
            if let Err(e) = result {
                error!("Application error: {:#}", e);
                return Err(e);
            }
        }
        _ = shutdown_rx.recv() => {
            info!("Shutting down gracefully");
        }
    }

    Ok(())
}
-e 

=== /home/amuldotexe/Desktop/GitHub202410/parseltongue/phase01/src/core/error.rs ===
//! Error Handling Infrastructure
//! 
//! Pyramid Structure:
//! 
//! Level 4 (Top): Error Context & Recovery
//! - ErrorExt trait      (adds context to errors)
//! - CircuitBreaker      (prevents cascading failures)
//! - Metrics integration (tracks error patterns)
//! 
//! Level 3: Error Categories
//! - IO/System Errors    (file, network)
//! - Domain Errors       (ZIP, DB operations)
//! - Resource Errors     (pools, limits)
//! - Runtime Errors      (async, cancellation)
//! 
//! Level 2: Error State Management
//! - CircuitState        (breaker state machine)
//! - Error propagation   (From implementations)
//! - Failure tracking    (metrics collection)
//! 
//! Level 1 (Base): Core Error Types
//! - Error enum          (comprehensive error types)
//! - Result type         (error type alias)
//! - Basic error traits  (Error, Display)

use std::{io, path::PathBuf};
use thiserror::Error;
use tokio::time::error::Elapsed;
use std::sync::Arc;
use metrics::{Counter, Gauge};
use std::time::Duration;
use tokio::sync::Mutex;

/// Core error types for the ZIP processing system
#[derive(Error, Debug)]
pub enum Error {
    #[error("IO error: {0}")]
    Io(#[from] io::Error),

    #[error("ZIP error: {0}")]
    Zip(#[from] zip::result::ZipError),

    #[error("Database error: {0}")]
    Database(#[from] sled::Error),

    #[error("Encoding error: {0}")]
    Encoding(#[from] std::string::FromUtf8Error),

    #[error("Operation timed out after {0:?}")]
    Timeout(Duration, #[source] Box<Elapsed>),

    #[error("Resource limit exceeded: {0}")]
    ResourceLimit(String),

    #[error("Invalid path: {0}")]
    InvalidPath(PathBuf),

    #[error("Circuit breaker open: {0}")]
    CircuitBreakerOpen(String),

    #[error("Task cancelled")]
    Cancelled,

    #[error("Shutdown in progress")]
    Shutdown,

    // Additional error types for async operations
    #[error("Buffer pool exhausted")]
    BufferPoolExhausted,

    #[error("Connection pool exhausted")]
    ConnectionPoolExhausted,

    #[error("Invalid ZIP entry: {0}")]
    InvalidZipEntry(String),

    #[error("Metrics error: {0}")]
    MetricsError(String),
}

/// Result type alias for our error type
pub type Result<T> = std::result::Result<T, Error>;

/// Circuit breaker state machine for handling cascading failures
#[derive(Debug, Clone, Copy)]
enum CircuitState {
    /// Normal operation, accepting requests
    Closed,
    /// Not accepting requests until specified time
    Open { until: std::time::Instant },
    /// Testing if service has recovered
    HalfOpen,
}

/// Circuit breaker for preventing cascading failures in async operations.
/// Implements the circuit breaker pattern with metrics tracking.
pub struct CircuitBreaker {
    name: String,
    failures: Counter,
    state: Arc<Mutex<CircuitState>>,
    threshold: u64,
    reset_after: Duration,
    last_failure: Gauge,
}

impl CircuitBreaker {
    /// Creates a new circuit breaker with specified parameters
    pub fn new(name: &str, threshold: u64, reset_after: Duration) -> Self {
        let failures = metrics::counter!("circuit_breaker_failures", "name" => name.to_string());
        let last_failure = metrics::gauge!("circuit_breaker_last_failure", "name" => name.to_string());
        
        Self {
            name: name.to_string(),
            failures,
            state: Arc::new(Mutex::new(CircuitState::Closed)),
            threshold,
            reset_after,
            last_failure,
        }
    }

    /// Executes an async operation with circuit breaker protection
    pub async fn call<F, Fut, T>(&self, f: F) -> Result<T>
    where
        F: FnOnce() -> Fut,
        Fut: std::future::Future<Output = Result<T>>,
    {
        let mut state = self.state.lock().await;

        match *state {
            CircuitState::Open { until } if until > std::time::Instant::now() => {
                tracing::warn!(breaker = self.name, "Circuit breaker open");
                return Err(Error::CircuitBreakerOpen(self.name.clone()));
            }
            CircuitState::Open { .. } => {
                tracing::info!(breaker = self.name, "Circuit breaker entering half-open state");
                *state = CircuitState::HalfOpen;
            }
            _ => {}
        }

        let result = f().await;

        match result {
            Ok(value) => {
                if matches!(*state, CircuitState::HalfOpen) {
                    tracing::info!(breaker = self.name, "Circuit breaker reset");
                    *state = CircuitState::Closed;
                    self.failures.reset();
                }
                Ok(value)
            }
            Err(e) => {
                self.failures.increment(1);
                self.last_failure.set(std::time::SystemTime::now()
                    .duration_since(std::time::UNIX_EPOCH)
                    .unwrap_or_default()
                    .as_secs() as f64);

                if self.failures.get() >= self.threshold {
                    tracing::error!(
                        breaker = self.name,
                        failures = self.failures.get(),
                        "Circuit breaker tripped"
                    );
                    *state = CircuitState::Open {
                        until: std::time::Instant::now() + self.reset_after,
                    };
                }
                Err(e)
            }
        }
    }

    /// Returns current failure count
    pub fn failure_count(&self) -> u64 {
        self.failures.get()
    }

    /// Manually reset the circuit breaker
    pub async fn reset(&self) {
        let mut state = self.state.lock().await;
        *state = CircuitState::Closed;
        self.failures.reset();
    }
}

/// Extension trait for adding context to errors
pub trait ErrorExt<T> {
    fn with_context<C>(self, context: C) -> Result<T>
    where
        C: std::fmt::Display + Send + Sync + 'static;
}

impl<T, E> ErrorExt<T> for std::result::Result<T, E>
where
    E: Into<Error>,
{
    fn with_context<C>(self, context: C) -> Result<T>
    where
        C: std::fmt::Display + Send + Sync + 'static,
    {
        self.map_err(|e| {
            let err: Error = e.into();
            tracing::error!(?err, context = %context, "Operation failed");
            err
        })
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tokio::time::sleep;

    #[tokio::test]
    async fn test_circuit_breaker_basic_operation() {
        let breaker = CircuitBreaker::new("test", 3, Duration::from_millis(100));

        // Test successful calls
        let result = breaker.call(|| async { Ok::<_, Error>(42) }).await;
        assert!(result.is_ok());

        // Test failure threshold
        for _ in 0..3 {
            let _ = breaker.call(|| async { 
                Err(Error::ResourceLimit("test".to_string())) 
            }).await;
        }

        // Circuit should be open now
        let result = breaker.call(|| async { Ok::<_, Error>(42) }).await;
        assert!(matches!(result, Err(Error::CircuitBreakerOpen(_))));

        // Wait for reset
        sleep(Duration::from_millis(150)).await;

        // Circuit should be half-open and accept calls
        let result = breaker.call(|| async { Ok::<_, Error>(42) }).await;
        assert!(result.is_ok());
    }

    #[tokio::test]
    async fn test_error_context() {
        let result: Result<()> = Err(Error::ResourceLimit("memory".to_string()))
            .with_context("Failed to allocate buffer");
        
        assert!(matches!(result, Err(Error::ResourceLimit(_))));
    }

    #[tokio::test]
    async fn test_circuit_breaker_metrics() {
        let breaker = CircuitBreaker::new("test_metrics", 2, Duration::from_millis(50));
        
        // Cause some failures
        for _ in 0..2 {
            let _ = breaker.call(|| async { 
                Err(Error::ResourceLimit("test".to_string())) 
            }).await;
        }

        assert_eq!(breaker.failure_count(), 2);
        
        // Reset and verify metrics are cleared
        breaker.reset().await;
        assert_eq!(breaker.failure_count(), 0);
    }
}
-e 

=== /home/amuldotexe/Desktop/GitHub202410/parseltongue/phase01/src/core/channel.rs ===
//! Async Channel Infrastructure
//! 
//! Pyramid Structure:
//! Level 4 (Top): Channel Coordination
//! Level 3: Backpressure Management
//! Level 2: Channel Implementation
//! Level 1 (Base): Core Channel Types

use std::sync::Arc;
use tokio::sync::{mpsc, Semaphore, RwLock};
use futures::{Stream, StreamExt};
use std::time::{Duration, Instant};
use metrics::{Counter, Gauge, Histogram};
use crate::core::{error::{Error, Result}, types::*};
use tracing::{info, warn, error};
use std::pin::Pin;
use std::task::{Context, Poll};
use tokio_stream::Stream;
use futures::ready;

// ===== Level 1: Core Channel Types =====

#[derive(Debug, Clone)]
pub struct ChannelConfig {
    pub buffer_size: usize,
    pub high_water_mark: usize,
    pub low_water_mark: usize,
    pub metrics_enabled: bool,
}

// ===== Level 2: Channel Implementation =====

/// Async channel with backpressure
pub struct AsyncChannel<T> {
    tx: mpsc::Sender<T>,
    config: ChannelConfig,
    metrics: Arc<Metrics>,
    backpressure: Arc<BackpressureControl>,
}

/// Metrics collection - Now using interior mutability correctly
#[derive(Debug)]
struct Metrics {
    messages_sent: Counter,
    queue_size: Gauge,
    latency: Histogram,
    backpressure_events: Counter,
}

impl Metrics {
    fn new() -> Self {
        Self {
            messages_sent: Counter::new(),
            queue_size: Gauge::new(),
            latency: Histogram::new(),
            backpressure_events: Counter::new(),
        }
    }
}

/// Backpressure control with proper synchronization
#[derive(Debug)]
struct BackpressureControl {
    permits: Arc<Semaphore>,
    state: Arc<RwLock<BackpressureState>>,
}

#[derive(Debug, Clone)]
struct BackpressureState {
    is_active: bool,
    last_trigger: Instant,
    trigger_count: u64,
}

impl BackpressureControl {
    fn new(high: usize, low: usize) -> Self {
        Self {
            permits: Arc::new(Semaphore::new(high)),
            state: Arc::new(RwLock::new(BackpressureState {
                is_active: false,
                last_trigger: Instant::now(),
                trigger_count: 0,
            })),
        }
    }

    async fn acquire(&self) -> Result<BackpressureGuard> {
        let permit = self.permits.acquire().await?;
        
        let mut state = self.state.write().await;
        if !state.is_active && self.permits.available_permits() <= self.low_water_mark() {
            state.is_active = true;
            state.last_trigger = Instant::now();
            state.trigger_count += 1;
        }

        Ok(BackpressureGuard {
            permit,
            control: self.clone(),
        })
    }

    fn low_water_mark(&self) -> usize {
        self.permits.available_permits() / 4
    }

    fn try_acquire(&self) -> Result<BackpressureGuard> {
        match self.permits.try_acquire() {
            Ok(permit) => {
                let mut state = self.state.blocking_lock();
                if !state.is_active && self.permits.available_permits() <= self.low_water_mark() {
                    state.is_active = true;
                    state.last_trigger = Instant::now();
                    state.trigger_count += 1;
                }
                Ok(BackpressureGuard {
                    permit,
                    control: self.clone(),
                })
            }
            Err(_) => Err(Error::ResourceLimit("Backpressure active".into()))
        }
    }
}

// RAII guard for backpressure permits
struct BackpressureGuard {
    permit: tokio::sync::SemaphorePermit<'static>,
    control: BackpressureControl,
}

impl<T> AsyncChannel<T>
where
    T: Send + 'static,
{
    pub fn new(config: ChannelConfig) -> (Self, mpsc::Receiver<T>) {
        let (tx, rx) = mpsc::channel(config.buffer_size);
        let metrics = Arc::new(Metrics::new());
        let backpressure = Arc::new(BackpressureControl::new(
            config.high_water_mark,
            config.low_water_mark,
        ));

        (Self {
            tx,
            config,
            metrics,
            backpressure,
        }, rx)
    }

    pub async fn send(&self, value: T) -> Result<()> {
        let start = Instant::now();
        
        // Get backpressure permit
        let _guard = self.backpressure.acquire().await?;

        // Send message
        self.tx.send(value).await.map_err(|_| Error::ChannelClosed)?;

        // Update metrics atomically
        self.metrics.messages_sent.increment(1);
        self.metrics.latency.record(start.elapsed());
        
        Ok(())
    }

    pub fn metrics(&self) -> &Metrics {
        &self.metrics
    }
}

impl<T> Stream for AsyncChannel<T> 
where
    T: Send + 'static,
{
    type Item = Result<T>;

    fn poll_next(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Option<Self::Item>> {
        // First check backpressure
        match self.backpressure.try_acquire() {
            Ok(_permit) => {
                // We have capacity, try to receive message
                match ready!(self.rx.poll_recv(cx)) {
                    Some(msg) => {
                        // Update metrics
                        self.metrics.messages_received.increment(1);
                        Poll::Ready(Some(Ok(msg)))
                    }
                    None => {
                        // Channel closed
                        Poll::Ready(None)
                    }
                }
            }
            Err(_) => {
                // Backpressure active, yield to runtime
                self.metrics.backpressure_events.increment(1);
                cx.waker().wake_by_ref();
                Poll::Pending
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tokio::time::sleep;
    use tokio_stream::StreamExt;

    #[tokio::test]
    async fn test_channel_backpressure() {
        let config = ChannelConfig {
            buffer_size: 10,
            high_water_mark: 8,
            low_water_mark: 2,
            metrics_enabled: true,
        };

        let (channel, mut rx) = AsyncChannel::new(config);

        // Spawn consumer
        tokio::spawn(async move {
            while let Some(_) = rx.recv().await {
                sleep(Duration::from_millis(10)).await;
            }
        });

        // Test sending with backpressure
        for i in 0..20 {
            channel.send(i).await.unwrap();
        }

        assert!(channel.metrics().messages_sent.get() > 0);
    }

    #[tokio::test]
    async fn test_channel_stream() {
        let config = ChannelConfig {
            buffer_size: 10,
            high_water_mark: 8,
            low_water_mark: 2,
            metrics_enabled: true,
        };

        let (channel, _rx) = AsyncChannel::new(config);
        
        // Send some test messages
        for i in 0..5 {
            channel.send(i).await.unwrap();
        }

        // Use as stream
        let mut count = 0;
        let mut stream = channel.take(5);
        
        while let Some(Ok(_msg)) = stream.next().await {
            count += 1;
        }

        assert_eq!(count, 5);
        assert!(channel.metrics().backpressure_events.get() >= 0);
    }
}
-e 

=== /home/amuldotexe/Desktop/GitHub202410/parseltongue/phase01/src/core/runtime/metrics.rs ===
//! Runtime Performance Metrics
//! 
//! Pyramid Structure:
//! 
//! Level 4 (Top): Metrics Aggregation
//! - MetricsAggregator  (combines all runtime metrics)
//!    Performance summaries
//!    Resource utilization
//!    System health
//! 
//! Level 3: Component Metrics
//! - WorkerMetrics     (worker performance)
//!    Task throughput
//!    Queue depths
//!    Processing latency
//! 
//! Level 2: Resource Metrics
//! - ResourceMetrics   (resource usage)
//!    Memory tracking
//!    CPU utilization
//!    I/O statistics
//! 
//! Level 1 (Base): Core Metric Types
//! - MetricTypes      (foundational types)
//!    Counters
//!    Gauges
//!    Histograms

use std::sync::Arc;
use metrics::{Counter, Gauge, Histogram};
use tokio::sync::RwLock;
use crate::core::{error::Result, types::*};

// ===== Level 1: Core Metric Types =====
// Design Choice: Using atomic metrics for lock-free updates

/// Core runtime metrics
#[derive(Debug)]
pub struct RuntimeMetrics {
    /// Tasks processed
    pub tasks_completed: Counter,
    /// Active workers
    pub active_workers: Gauge,
    /// Task latency
    pub task_latency: Histogram,
    /// Memory usage
    pub memory_usage: Gauge,
    /// CPU usage
    pub cpu_usage: Gauge,
}

// ===== Level 2: Resource Metrics =====
// Design Choice: Using RwLock for infrequent updates

/// Resource utilization metrics
pub struct ResourceMetrics {
    /// Memory metrics
    memory: Arc<MemoryMetrics>,
    /// CPU metrics
    cpu: Arc<CpuMetrics>,
    /// I/O metrics
    io: Arc<IoMetrics>,
}

// ===== Level 3: Component Metrics =====
// Design Choice: Using channels for metric updates

/// Worker-specific metrics
pub struct WorkerMetrics {
    /// Tasks started
    pub tasks_started: Counter,
    /// Tasks completed
    pub tasks_completed: Counter,
    /// Tasks failed
    pub tasks_failed: Counter,
    /// Queue depth
    pub queue_depth: Gauge,
    /// Processing time
    pub processing_time: Histogram,
}

// ===== Level 4: Metrics Aggregation =====
// Design Choice: Using builder pattern for configuration

/// Metrics aggregator implementation
pub struct MetricsAggregator {
    /// Runtime metrics
    runtime: Arc<RuntimeMetrics>,
    /// Resource metrics
    resources: Arc<ResourceMetrics>,
    /// Worker metrics
    workers: Arc<RwLock<Vec<Arc<WorkerMetrics>>>>,
}

impl MetricsAggregator {
    /// Creates new metrics aggregator
    pub fn new() -> Self {
        Self {
            runtime: Arc::new(RuntimeMetrics::new()),
            resources: Arc::new(ResourceMetrics::new()),
            workers: Arc::new(RwLock::new(Vec::new())),
        }
    }

    /// Records task completion
    pub fn record_task_completion(&self, duration: Duration) {
        self.runtime.tasks_completed.increment(1);
        self.runtime.task_latency.record(duration);
    }

    /// Updates resource metrics
    pub async fn update_resources(&self) -> Result<()> {
        // Update memory metrics
        let mem_info = sys_info::mem_info()?;
        self.runtime.memory_usage.set(mem_info.total as f64);

        // Update CPU metrics
        let cpu_load = sys_info::loadavg()?;
        self.runtime.cpu_usage.set(cpu_load.one);

        Ok(())
    }

    /// Registers worker metrics
    pub async fn register_worker(&self, metrics: Arc<WorkerMetrics>) {
        self.runtime.active_workers.increment(1.0);
        self.workers.write().await.push(metrics);
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tokio::time::sleep;

    #[tokio::test]
    async fn test_metrics_aggregation() {
        let aggregator = MetricsAggregator::new();
        
        // Record some metrics
        aggregator.record_task_completion(Duration::from_millis(100));
        
        // Update resources
        aggregator.update_resources().await.unwrap();
        
        // Register worker
        let worker_metrics = Arc::new(WorkerMetrics::new("test-worker"));
        aggregator.register_worker(worker_metrics).await;
        
        // Verify metrics
        assert_eq!(aggregator.runtime.tasks_completed.get(), 1);
        assert_eq!(aggregator.runtime.active_workers.get(), 1.0);
    }
}
-e 

=== /home/amuldotexe/Desktop/GitHub202410/parseltongue/phase01/src/core/runtime/shutdown.rs ===
//! Graceful Shutdown Management
//! 
//! Pyramid Structure:
//! 
//! Level 4 (Top): Shutdown Orchestration
//! - ShutdownManager    (coordinates shutdown)
//!    Phase management
//!    Resource cleanup
//!    Timeout handling
//! 
//! Level 3: Component Shutdown
//! - ComponentManager   (subsystem shutdown)
//!    Worker shutdown
//!    Task cancellation
//!    Connection cleanup
//! 
//! Level 2: Resource Cleanup
//! - ResourceManager   (cleanup coordination)
//!    Memory reclamation
//!    Handle closure
//!    State cleanup
//! 
//! Level 1 (Base): Shutdown Types
//! - Core Types        (foundational types)
//!    Shutdown states
//!    Cleanup traits
//!    Error types

use std::sync::Arc;
use tokio::sync::{broadcast, Mutex};
use tokio::time::{Duration, timeout, Instant};
use metrics::{Counter, Gauge, Histogram};
use futures::future::join_all;
use crate::core::{error::{Error, Result}, types::*};
use tracing::{info, warn, error};

// ===== Level 1: Core Shutdown Types =====
// Design Choice: Using enums for explicit state transitions

/// Shutdown progress tracking
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum ShutdownPhase {
    /// Initial shutdown signal sent
    Initiated,
    /// Tasks are being drained
    DrainingSoftly,
    /// Force cancelling remaining tasks
    ForcingShutdown,
    /// All resources cleaned up
    Completed,
}

/// Shutdown progress metrics
#[derive(Debug)]
struct ShutdownMetrics {
    /// Active tasks remaining
    active_tasks: Gauge,
    /// Resources pending cleanup
    pending_resources: Gauge,
    /// Shutdown duration
    shutdown_duration: Histogram,
    /// Forced shutdowns counter
    forced_shutdowns: Counter,
}

// ===== Level 2: Resource Management =====
// Design Choice: Using async traits for cleanup

/// Resource cleanup tracking
#[async_trait::async_trait]
pub trait ResourceCleanup: Send + Sync {
    /// Cleanup resource
    async fn cleanup(&self) -> Result<()>;
    /// Force cleanup after timeout
    async fn force_cleanup(&self) -> Result<()>;
}

/// Connection draining implementation
pub struct ConnectionDraining {
    /// Active connections
    connections: Arc<Semaphore>,
    /// Drain timeout
    timeout: Duration,
    /// Metrics
    metrics: ShutdownMetrics,
}

// ===== Level 3: Component Shutdown =====
// Design Choice: Using builder pattern for configuration

/// Main shutdown manager
pub struct ShutdownManager {
    /// Shutdown configuration
    config: ShutdownConfig,
    /// Shutdown signal
    shutdown_tx: broadcast::Sender<()>,
    /// Resource cleanup handlers
    resources: Vec<Arc<dyn ResourceCleanup>>,
    /// Metrics
    metrics: Arc<ShutdownMetrics>,
    /// Current phase
    phase: Arc<Mutex<ShutdownPhase>>,
    /// Shutdown deadline
    deadline: Arc<Mutex<Option<Instant>>>,
}

impl ShutdownManager {
    /// Creates new shutdown manager
    pub fn new(config: ShutdownConfig) -> Self {
        let (shutdown_tx, _) = broadcast::channel(1);
        
        Self {
            config,
            shutdown_tx,
            resources: Vec::new(),
            metrics: Arc::new(ShutdownMetrics::new()),
            phase: Arc::new(Mutex::new(ShutdownPhase::Initiated)),
            deadline: Arc::new(Mutex::new(None)),
        }
    }

    /// Register resource for cleanup
    pub fn register_resource(&mut self, resource: Arc<dyn ResourceCleanup>) {
        self.resources.push(resource);
        self.metrics.pending_resources.increment(1.0);
    }

    /// Initiate graceful shutdown
    pub async fn shutdown(self) -> Result<()> {
        let start = Instant::now();
        info!("Initiating graceful shutdown");

        // Set shutdown deadline
        *self.deadline.lock().await = Some(start + self.config.graceful_timeout);

        // Broadcast shutdown signal
        let _ = self.shutdown_tx.send(());
        
        // Update phase
        *self.phase.lock().await = ShutdownPhase::DrainingSoftly;

        // Try graceful cleanup with deadline
        let deadline = *self.deadline.lock().await.as_ref().unwrap();
        let remaining_time = deadline.saturating_duration_since(Instant::now());

        match timeout(remaining_time, self.cleanup_resources()).await {
            Ok(Ok(_)) => {
                info!("Graceful shutdown completed successfully");
                *self.phase.lock().await = ShutdownPhase::Completed;
            }
            _ => {
                warn!("Graceful shutdown timed out, forcing cleanup");
                *self.phase.lock().await = ShutdownPhase::ForcingShutdown;
                self.metrics.forced_shutdowns.increment(1);
                
                // Force cleanup with short timeout
                let force_timeout = Duration::from_secs(5);
                match timeout(force_timeout, self.force_cleanup_resources()).await {
                    Ok(Ok(_)) => info!("Forced cleanup completed"),
                    _ => error!("Forced cleanup failed"),
                }
            }
        }

        self.metrics.shutdown_duration.record(start.elapsed());
        Ok(())
    }

    /// Cleanup resources gracefully
    async fn cleanup_resources(&self) -> Result<()> {
        let futures: Vec<_> = self.resources.iter()
            .map(|r| r.cleanup())
            .collect();

        for result in join_all(futures).await {
            if let Err(e) = result {
                error!("Resource cleanup failed: {}", e);
            }
            self.metrics.pending_resources.decrement(1.0);
        }

        Ok(())
    }

    /// Force cleanup of resources
    async fn force_cleanup_resources(&self) -> Result<()> {
        let futures: Vec<_> = self.resources.iter()
            .map(|r| r.force_cleanup())
            .collect();

        join_all(futures).await
            .into_iter()
            .collect::<Result<Vec<_>>>()?;

        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::time::Duration;
    use tokio::time::sleep;

    struct TestResource {
        cleanup_duration: Duration,
    }

    #[async_trait::async_trait]
    impl ResourceCleanup for TestResource {
        async fn cleanup(&self) -> Result<()> {
            sleep(self.cleanup_duration).await;
            Ok(())
        }

        async fn force_cleanup(&self) -> Result<()> {
            Ok(())
        }
    }

    #[tokio::test]
    async fn test_graceful_shutdown() {
        let config = ShutdownConfig {
            graceful_timeout: Duration::from_secs(1),
            force_after_timeout: true,
        };

        let mut manager = ShutdownManager::new(config);
        
        // Add quick resource
        manager.register_resource(Arc::new(TestResource {
            cleanup_duration: Duration::from_millis(100),
        }));

        assert!(manager.shutdown().await.is_ok());
    }

    #[tokio::test]
    async fn test_forced_shutdown() {
        let config = ShutdownConfig {
            graceful_timeout: Duration::from_millis(100),
            force_after_timeout: true,
        };

        let mut manager = ShutdownManager::new(config);
        
        // Add slow resource
        manager.register_resource(Arc::new(TestResource {
            cleanup_duration: Duration::from_secs(1),
        }));

        assert!(manager.shutdown().await.is_ok());
    }
}
-e 

=== /home/amuldotexe/Desktop/GitHub202410/parseltongue/phase01/src/core/runtime/worker.rs ===
//! Worker Thread Management
//! 
//! Pyramid Structure:
//! 
//! Level 4 (Top): Worker Coordination
//! - WorkerGroup       (worker pool management)
//!    Load balancing
//!    Worker lifecycle
//!    Pool metrics
//! 
//! Level 3: Task Distribution
//! - TaskDispatcher    (task handling)
//!    Priority queuing
//!    Backpressure
//!    Task routing
//! 
//! Level 2: Worker Implementation
//! - Worker           (single worker)
//!    Task execution
//!    State management
//!    Error handling
//! 
//! Level 1 (Base): Worker Types
//! - Core Types       (foundational)
//!    Configuration
//!    Task definitions
//!    Metrics types

use std::sync::Arc;
use tokio::sync::{mpsc, Semaphore};
use tokio::task::JoinHandle;
use futures::Future;
use metrics::{Counter, Gauge, Histogram};
use std::time::{Duration, Instant};
use crate::core::{error::{Error, Result}, types::*};
use tracing::{info, warn, error, Instrument};

// ===== Level 1: Core Worker Types =====
// Design Choice: Using strong typing for worker configuration

/// Individual worker configuration
#[derive(Debug, Clone)]
pub struct WorkerConfig {
    /// Worker identifier
    pub id: String,
    /// Queue capacity
    pub queue_capacity: usize,
    /// Task execution timeout
    pub task_timeout: Duration,
    /// Metrics enabled
    pub metrics_enabled: bool,
}

/// Task definition with metadata
#[derive(Debug)]
pub struct TaskDefinition {
    /// Task identifier
    pub id: String,
    /// Task priority
    pub priority: TaskPriority,
    /// Task future
    pub future: Pin<Box<dyn Future<Output = Result<()>> + Send>>,
    /// Task metadata
    pub metadata: TaskMetadata,
}

// ===== Level 2: Worker Implementation =====
// Design Choice: Using async traits for worker behavior

/// Individual worker implementation
pub struct Worker {
    /// Worker configuration
    config: WorkerConfig,
    /// Task receiver
    task_rx: mpsc::Receiver<TaskDefinition>,
    /// Shutdown signal
    shutdown: broadcast::Receiver<()>,
    /// Worker metrics
    metrics: WorkerMetrics,
    /// Worker state
    state: Arc<WorkerState>,
}

/// Worker state management
#[derive(Debug)]
struct WorkerState {
    /// Active tasks counter
    active_tasks: AtomicUsize,
    /// Worker status
    status: AtomicEnum<WorkerStatus>,
    /// Last heartbeat
    last_heartbeat: AtomicTime,
}

// ===== Level 3: Task Management =====
// Design Choice: Using priority queue for task scheduling

/// Priority-based task queue
pub struct TaskQueue {
    /// High priority queue
    high: mpsc::Sender<TaskDefinition>,
    /// Normal priority queue
    normal: mpsc::Sender<TaskDefinition>,
    /// Low priority queue
    low: mpsc::Sender<TaskDefinition>,
    /// Queue metrics
    metrics: QueueMetrics,
}

/// Task dispatcher implementation
pub struct TaskDispatcher {
    /// Task queues
    queues: Arc<TaskQueue>,
    /// Worker pool
    workers: Arc<WorkerGroup>,
    /// Backpressure control
    backpressure: Arc<BackpressureControl>,
}

// ===== Level 4: Worker Coordination =====
// Design Choice: Using Arc for shared state

impl Worker {
    /// Creates a new worker with given configuration
    pub fn new(config: WorkerConfig, shutdown: broadcast::Receiver<()>) -> Result<(Self, mpsc::Sender<TaskDefinition>)> {
        let (task_tx, task_rx) = mpsc::channel(config.queue_capacity);
        let metrics = WorkerMetrics::new(&config.id);
        let state = Arc::new(WorkerState::new());

        Ok((Self {
            config,
            task_rx,
            shutdown,
            metrics,
            state,
        }, task_tx))
    }

    /// Starts the worker processing loop
    pub async fn run(mut self) -> Result<()> {
        info!(worker.id = %self.config.id, "Worker starting");
        
        let mut shutdown = self.shutdown.resubscribe();
        
        loop {
            tokio::select! {
                // Handle shutdown signal
                _ = shutdown.recv() => {
                    info!(worker.id = %self.config.id, "Worker received shutdown signal");
                    break;
                }
                
                // Process tasks
                Some(task) = self.task_rx.recv() => {
                    self.process_task(task).await?;
                }
            }
        }

        self.shutdown_gracefully().await
    }

    /// Processes a single task
    async fn process_task(&mut self, task: TaskDefinition) -> Result<()> {
        let start = Instant::now();
        let task_id = task.id.clone();
        
        self.metrics.tasks_started.increment(1);
        self.state.active_tasks.fetch_add(1, Ordering::SeqCst);

        let result = tokio::time::timeout(
            self.config.task_timeout,
            task.future
        ).await;

        self.state.active_tasks.fetch_sub(1, Ordering::SeqCst);
        
        match result {
            Ok(Ok(_)) => {
                self.metrics.tasks_completed.increment(1);
                self.metrics.task_duration.record(start.elapsed());
                info!(worker.id = %self.config.id, task.id = %task_id, "Task completed successfully");
            }
            Ok(Err(e)) => {
                self.metrics.tasks_failed.increment(1);
                error!(worker.id = %self.config.id, task.id = %task_id, error = ?e, "Task failed");
            }
            Err(_) => {
                self.metrics.tasks_timeout.increment(1);
                warn!(worker.id = %self.config.id, task.id = %task_id, "Task timed out");
            }
        }

        Ok(())
    }

    /// Performs graceful shutdown
    async fn shutdown_gracefully(self) -> Result<()> {
        info!(worker.id = %self.config.id, "Worker shutting down gracefully");
        
        // Wait for active tasks to complete
        while self.state.active_tasks.load(Ordering::SeqCst) > 0 {
            tokio::time::sleep(Duration::from_millis(100)).await;
        }

        info!(worker.id = %self.config.id, "Worker shutdown complete");
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tokio::time::sleep;

    #[tokio::test]
    async fn test_worker_basic_operation() {
        let (shutdown_tx, shutdown_rx) = broadcast::channel(1);
        
        let config = WorkerConfig {
            id: "test-worker".into(),
            queue_capacity: 10,
            task_timeout: Duration::from_secs(1),
            metrics_enabled: true,
        };

        let (worker, task_tx) = Worker::new(config, shutdown_rx).unwrap();
        
        // Spawn worker
        let worker_handle = tokio::spawn(async move {
            worker.run().await
        });

        // Send a test task
        let task = TaskDefinition {
            id: "test-task".into(),
            priority: TaskPriority::Normal,
            future: Box::pin(async { 
                sleep(Duration::from_millis(100)).await;
                Ok(())
            }),
            metadata: TaskMetadata::default(),
        };

        task_tx.send(task).await.unwrap();
        
        // Initiate shutdown
        sleep(Duration::from_millis(200)).await;
        shutdown_tx.send(()).unwrap();
        
        // Worker should complete gracefully
        let result = worker_handle.await.unwrap();
        assert!(result.is_ok());
    }
}
-e 

=== /home/amuldotexe/Desktop/GitHub202410/parseltongue/phase01/src/core/runtime/mod.rs ===
//! Runtime Management Infrastructure
//! 
//! Pyramid Structure:
//! 
//! Level 4 (Top): Runtime Orchestration
//! - RuntimeManager     (coordinates all runtime components)
//!    Lifecycle management
//!    Resource coordination
//!    Global state handling
//! 
//! Level 3: Resource Management
//! - WorkerPoolManager (manages worker threads)
//!    Thread pool administration
//!    Load distribution
//!    Resource monitoring
//! 
//! Level 2: Task Management
//! - TaskScheduler     (schedules async tasks)
//!    Priority handling
//!    Backpressure control
//!    Performance tracking
//! 
//! Level 1 (Base): Core Runtime Types
//! - Configuration    (runtime settings)
//!    Worker settings
//!    Resource limits
//!    Shutdown parameters

use std::sync::Arc;
use tokio::sync::{Semaphore, broadcast, mpsc};
use tokio::task::JoinSet;
use metrics::{Counter, Gauge, Histogram};
use std::time::Duration;
use crate::core::{error::{Error, Result}, types::*};

// ===== Level 1: Core Runtime Types =====
// Design Choice: Using builder pattern for flexible configuration

/// Runtime configuration with all settings
#[derive(Debug, Clone)]
pub struct RuntimeConfig {
    /// Worker thread configuration
    pub worker_config: WorkerConfig,
    /// Resource limits
    pub resource_limits: ResourceLimits,
    /// Shutdown configuration
    pub shutdown_config: ShutdownConfig,
}

/// Worker-specific configuration
#[derive(Debug, Clone)]
pub struct WorkerConfig {
    /// Number of worker threads
    pub thread_count: usize,
    /// Task queue capacity per worker
    pub queue_capacity: usize,
    /// Worker stack size
    pub stack_size: usize,
}

/// Shutdown-specific configuration
#[derive(Debug, Clone)]
pub struct ShutdownConfig {
    /// Graceful shutdown timeout
    pub timeout: Duration,
    /// Force shutdown after timeout
    pub force_after_timeout: bool,
}

// ===== Level 2: Task Management =====
// Design Choice: Using channels for task communication

/// Task scheduler implementation
pub struct TaskScheduler {
    /// Task submission channel
    task_tx: mpsc::Sender<Task>,
    /// Priority queue for tasks
    priority_queue: Arc<PriorityQueue>,
    /// Task metrics
    metrics: TaskMetrics,
}

/// Task representation
#[derive(Debug)]
pub struct Task {
    /// Task priority
    priority: TaskPriority,
    /// Task future
    future: Pin<Box<dyn Future<Output = Result<()>> + Send>>,
    /// Task metadata
    metadata: TaskMetadata,
}

/// Task performance metrics
#[derive(Debug)]
struct TaskMetrics {
    /// Tasks completed counter
    completed: Counter,
    /// Task latency histogram
    latency: Histogram,
    /// Active tasks gauge
    active: Gauge,
}

// ===== Level 3: Resource Management =====
// Design Choice: Using atomic types for thread-safe metrics

/// Worker pool manager
pub struct WorkerPoolManager {
    /// Worker join handles
    workers: JoinSet<Result<()>>,
    /// Worker semaphore
    capacity: Arc<Semaphore>,
    /// Resource monitor
    resources: Arc<ResourceMonitor>,
}

/// Resource monitoring
pub struct ResourceMonitor {
    /// Memory usage gauge
    memory_usage: Gauge,
    /// CPU usage gauge
    cpu_usage: Gauge,
    /// Resource limits
    limits: ResourceLimits,
}

// ===== Level 4: Runtime Orchestration =====
// Design Choice: Using Arc for shared state

/// Main runtime manager
pub struct RuntimeManager {
    /// Worker pool
    workers: Arc<WorkerPoolManager>,
    /// Task scheduler
    scheduler: Arc<TaskScheduler>,
    /// Shutdown signal
    shutdown: broadcast::Sender<()>,
    /// Runtime metrics
    metrics: RuntimeMetrics,
}

impl RuntimeManager {
    /// Creates a new runtime manager with given configuration
    pub async fn new(config: RuntimeConfig) -> Result<Self> {
        let (shutdown_tx, _) = broadcast::channel(1);
        
        let workers = Arc::new(WorkerPoolManager::new(
            config.worker_config,
            config.resource_limits.clone(),
        )?);

        let scheduler = Arc::new(TaskScheduler::new(
            config.worker_config.queue_capacity,
        )?);

        Ok(Self {
            workers,
            scheduler,
            shutdown: shutdown_tx,
            metrics: RuntimeMetrics::new(),
        })
    }

    /// Spawns a task with given priority
    pub async fn spawn<F>(&self, priority: TaskPriority, future: F) -> Result<()>
    where
        F: Future<Output = Result<()>> + Send + 'static,
    {
        let task = Task {
            priority,
            future: Box::pin(future),
            metadata: TaskMetadata::new(),
        };

        self.scheduler.schedule(task).await
    }

    /// Initiates graceful shutdown
    pub async fn shutdown(self) -> Result<()> {
        tracing::info!("Initiating graceful shutdown");
        let _ = self.shutdown.send(());
        
        // Wait for workers to complete
        self.workers.shutdown().await?;
        
        tracing::info!("Runtime shutdown complete");
        Ok(())
    }
}

// Implement supporting types...
mod worker;
mod shutdown;

pub use worker::Worker;
pub use shutdown::ShutdownManager;

#[cfg(test)]
mod tests {
    use super::*;
    use tokio::time::sleep;

    #[tokio::test]
    async fn test_runtime_basic_operation() {
        let config = RuntimeConfig {
            worker_config: WorkerConfig {
                thread_count: 2,
                queue_capacity: 100,
                stack_size: 3 * 1024 * 1024,
            },
            resource_limits: ResourceLimits {
                max_tasks: 10,
                max_memory: 1024 * 1024 * 1024,
                max_connections: 5,
            },
            shutdown_config: ShutdownConfig {
                timeout: Duration::from_secs(5),
                force_after_timeout: true,
            },
        };

        let runtime = RuntimeManager::new(config).await.unwrap();

        // Spawn a test task
        runtime.spawn(TaskPriority::Normal, async {
            sleep(Duration::from_millis(100)).await;
            Ok(())
        }).await.unwrap();

        // Shutdown should complete gracefully
        runtime.shutdown().await.unwrap();
    }
}
-e 

=== /home/amuldotexe/Desktop/GitHub202410/parseltongue/phase01/src/core/mod.rs ===
//! Core Infrastructure Layer
//! 
//! Pyramid Structure:
//! 
//! Level 4 (Top): Core Coordination
//! - Core API         (public interface)
//! - Error Handling   (error propagation)
//! - Type System      (type coordination)
//! 
//! Level 3: Module Management
//! - Channel System   (async channels)
//! - Runtime System   (async runtime)
//! - Type System      (core types)
//! 
//! Level 2: Error Management
//! - Error Types      (error definitions)
//! - Error Handling   (error processing)
//! 
//! Level 1 (Base): Module Exports
//! - Public Exports   (module visibility)
//! - Type Exports     (type visibility)

pub mod channel;
pub mod error;
pub mod types;
pub mod runtime;
-e 

=== /home/amuldotexe/Desktop/GitHub202410/parseltongue/phase01/src/core/types.rs ===
//! Core Domain Types
//! 
//! Pyramid Structure:
//! 
//! Level 4 (Top): High-Level Compositions
//! - RuntimeManager     (combines workers, resources, metrics)
//! - ProcessingPipeline (combines ZIP, storage, validation)
//! 
//! Level 3: Coordinating Types
//! - WorkerPool        (manages async tasks)
//! - StorageManager    (manages DB connections)
//! - ValidationManager (manages CRC checks)
//! 
//! Level 2: Operational Types
//! - ZipEntry         (represents ZIP contents)
//! - StorageEntry     (represents DB records)
//! - MetricsData      (represents performance data)
//! 
//! Level 1 (Base): Fundamental Types
//! - ResourceLimits   (control system boundaries)
//! - BufferConfig     (manage memory usage)
//! - ValidationConfig (control validation behavior)

use std::{path::PathBuf, time::Duration, sync::Arc};
use bytes::Bytes;
use serde::{Serialize, Deserialize};
use tokio::sync::Semaphore;

// ===== Level 1: Fundamental Types =====
// Design Choice: Using newtype pattern for type safety and semantic meaning

/// Resource limits for the system
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ResourceLimits {
    /// Maximum number of concurrent tasks
    pub max_tasks: usize,
    /// Maximum memory usage in bytes
    pub max_memory: usize,
    /// Maximum DB connections
    pub max_connections: usize,
}

/// Buffer configuration for streaming operations
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BufferConfig {
    /// Initial buffer size
    pub initial_size: usize,
    /// Maximum buffer size
    pub max_size: usize,
    /// Growth factor for adaptive sizing
    pub growth_factor: f32,
}

/// Validation configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ValidationConfig {
    /// Whether to validate CRC
    pub validate_crc: bool,
    /// Whether to validate file names
    pub validate_names: bool,
    /// Maximum parallel validations
    pub max_parallel: usize,
}

// ===== Level 2: Operational Types =====
// Design Choice: Using Arc for shared ownership in async context

/// Represents a ZIP file entry
#[derive(Debug, Clone)]
pub struct ZipEntry {
    /// Relative path within ZIP
    pub path: PathBuf,
    /// Entry contents
    pub content: Bytes,
    /// Content CRC32
    pub crc32: u32,
    /// Original size
    pub size: u64,
}

/// Represents a storage entry
#[derive(Debug, Clone)]
pub struct StorageEntry {
    /// Storage key
    pub key: String,
    /// Entry data
    pub data: Bytes,
    /// Metadata
    pub metadata: EntryMetadata,
}

/// Entry metadata
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EntryMetadata {
    /// Original path
    pub original_path: PathBuf,
    /// Content hash
    pub content_hash: String,
    /// Storage timestamp
    pub timestamp: chrono::DateTime<chrono::Utc>,
}

// ===== Level 3: Coordinating Types =====
// Design Choice: Using builder pattern for complex configurations

/// Worker pool configuration
#[derive(Debug, Clone)]
pub struct WorkerPool {
    /// Number of worker threads
    pub worker_threads: usize,
    /// Task priorities
    pub priorities: Vec<TaskPriority>,
    /// Resource semaphore
    pub semaphore: Arc<Semaphore>,
}

/// Storage manager configuration
#[derive(Debug, Clone)]
pub struct StorageManager {
    /// Connection pool size
    pub pool_size: usize,
    /// Batch size for writes
    pub batch_size: usize,
    /// Write timeout
    pub write_timeout: Duration,
}

// ===== Level 4: High-Level Compositions =====
// Design Choice: Using composition over inheritance

/// Runtime manager configuration
#[derive(Debug)]
pub struct RuntimeManager {
    /// Worker pool
    pub workers: WorkerPool,
    /// Resource limits
    pub limits: ResourceLimits,
    /// Buffer config
    pub buffers: BufferConfig,
    /// Validation config
    pub validation: ValidationConfig,
}

/// Processing pipeline configuration
#[derive(Debug)]
pub struct ProcessingPipeline {
    /// Storage manager
    pub storage: StorageManager,
    /// Worker pool
    pub workers: WorkerPool,
    /// Validation config
    pub validation: ValidationConfig,
}

// ===== Supporting Types =====

/// Task priority levels
#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]
pub enum TaskPriority {
    Low,
    Normal,
    High,
    Critical,
}

/// Builder for RuntimeManager
#[derive(Default)]
pub struct RuntimeManagerBuilder {
    workers: Option<WorkerPool>,
    limits: Option<ResourceLimits>,
    buffers: Option<BufferConfig>,
    validation: Option<ValidationConfig>,
}

impl RuntimeManagerBuilder {
    pub fn new() -> Self {
        Self::default()
    }

    pub fn workers(mut self, workers: WorkerPool) -> Self {
        self.workers = Some(workers);
        self
    }

    pub fn limits(mut self, limits: ResourceLimits) -> Self {
        self.limits = Some(limits);
        self
    }

    pub fn build(self) -> Result<RuntimeManager, crate::core::error::Error> {
        Ok(RuntimeManager {
            workers: self.workers.ok_or_else(|| 
                crate::core::error::Error::ResourceLimit("Workers not configured".into()))?,
            limits: self.limits.ok_or_else(|| 
                crate::core::error::Error::ResourceLimit("Limits not configured".into()))?,
            buffers: self.buffers.unwrap_or_default(),
            validation: self.validation.unwrap_or_default(),
        })
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_runtime_manager_builder() {
        let workers = WorkerPool {
            worker_threads: 4,
            priorities: vec![TaskPriority::Normal],
            semaphore: Arc::new(Semaphore::new(4)),
        };

        let limits = ResourceLimits {
            max_tasks: 10,
            max_memory: 1024 * 1024,
            max_connections: 5,
        };

        let manager = RuntimeManagerBuilder::new()
            .workers(workers)
            .limits(limits)
            .build();

        assert!(manager.is_ok());
    }
}
-e 

=== /home/amuldotexe/Desktop/GitHub202410/parseltongue/phase01/src/utils/resource.rs ===
//! Resource Management Infrastructure
//! 
//! Pyramid Structure:
//! 
//! Level 4 (Top): Resource Coordination
//! - ResourceManager   (manages resources)
//! - ResourceMetrics   (tracks resource usage)
//! - LoadBalancer      (balances resources)
//! 
//! Level 3: Resource Management
//! - ResourcePool      (manages resource pools)
//! - ResourceMonitor   (monitors resources)
//! - ResourceLimiter   (enforces limits)
//! 
//! Level 2: Resource Implementation
//! - Resource          (resource implementation)
//! - ResourceState     (resource lifecycle)
//! - ResourceMetrics   (resource stats)
//! 
//! Level 1 (Base): Core Resource Types
//! - ResourceConfig    (resource configuration)
//! - ResourceMetrics   (resource metrics)
//! - ResourceError     (resource errors)

use std::sync::Arc;
use tokio::sync::{Semaphore, Mutex};
use metrics::{Counter, Gauge};
use crate::core::{error::{Error, Result}, types::*};

// ===== Level 1: Core Resource Types =====
// Design Choice: Using generics for type safety

/// Resource configuration
#[derive(Debug, Clone)]
pub struct ResourceConfig {
    /// Maximum resources
    pub max_resources: usize,
    /// Resource timeout
    pub timeout: std::time::Duration,
    /// Enable metrics
    pub metrics_enabled: bool,
}

// ===== Level 2: Resource Implementation =====
// Design Choice: Using async traits for resources

/// Resource pool implementation
pub struct ResourcePool<T> {
    /// Available resources
    resources: Arc<Mutex<Vec<T>>>,
    /// Resource semaphore
    semaphore: Arc<Semaphore>,
    /// Pool configuration
    config: ResourceConfig,
    /// Pool metrics
    metrics: ResourceMetrics,
}

impl<T> ResourcePool<T>
where
    T: Send + 'static,
{
    /// Creates new resource pool
    pub fn new(config: ResourceConfig) -> Self {
        let resources = Arc::new(Mutex::new(Vec::with_capacity(config.max_resources)));
        let semaphore = Arc::new(Semaphore::new(config.max_resources));
        let metrics = ResourceMetrics::new();

        Self {
            resources,
            semaphore,
            config,
            metrics,
        }
    }

    /// Acquires resource from pool
    pub async fn acquire(&self) -> Result<ResourceGuard<T>> {
        let _permit = self.semaphore.acquire().await?;
        
        let mut resources = self.resources.lock().await;
        let resource = resources.pop()
            .ok_or_else(|| Error::ResourceLimit("No resources available".into()))?;

        self.metrics.active_resources.increment(1.0);
        
        Ok(ResourceGuard {
            resource: Some(resource),
            pool: self.clone(),
        })
    }

    /// Returns resource to pool
    async fn release(&self, resource: T) {
        self.resources.lock().await.push(resource);
        self.metrics.active_resources.decrement(1.0);
    }
}

// ===== Level 3: Resource Management =====
// Design Choice: Using RAII for resource management

/// Resource guard for automatic return
pub struct ResourceGuard<T> {
    /// Managed resource
    resource: Option<T>,
    /// Owner pool
    pool: ResourcePool<T>,
}

impl<T> Drop for ResourceGuard<T>
where
    T: Send + 'static,
{
    fn drop(&mut self) {
        if let Some(resource) = self.resource.take() {
            let pool = self.pool.clone();
            
            tokio::spawn(async move {
                pool.release(resource).await;
            });
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_resource_pool() {
        let config = ResourceConfig {
            max_resources: 10,
            timeout: std::time::Duration::from_secs(1),
            metrics_enabled: true,
        };

        let pool = ResourcePool::new(config);
        
        // Add test resource
        pool.resources.lock().await.push(42);
        
        // Test resource acquisition
        let guard = pool.acquire().await.unwrap();
        assert_eq!(*guard.resource.as_ref().unwrap(), 42);
        
        // Resource should be returned to pool on drop
        drop(guard);
        
        // Allow time for async release
        tokio::time::sleep(tokio::time::Duration::from_millis(10)).await;
        
        assert_eq!(pool.metrics.active_resources.get(), 0.0);
    }
}

-e 

=== /home/amuldotexe/Desktop/GitHub202410/parseltongue/phase01/src/utils/buffer.rs ===
//! Buffer Management Infrastructure
//! 
//! Pyramid Structure:
//! 
//! Level 4 (Top): Buffer Coordination
//! - BufferManager    (manages buffer pools)
//! - BufferMetrics    (tracks buffer usage)
//! - PoolBalancer     (balances pool load)
//! 
//! Level 3: Pool Management
//! - BufferPool       (manages buffer allocation)
//! - PoolMetrics      (tracks pool stats)
//! - ResizePolicy     (handles pool sizing)
//! 
//! Level 2: Buffer Implementation
//! - Buffer           (buffer implementation)
//! - BufferState      (buffer lifecycle)
//! - BufferMetrics    (buffer stats)
//! 
//! Level 1 (Base): Core Buffer Types
//! - BufferConfig     (buffer configuration)
//! - BufferMetrics    (buffer metrics)
//! - BufferError      (buffer errors)

use std::sync::Arc;
use tokio::sync::{Semaphore, Mutex};
use bytes::{Bytes, BytesMut};
use metrics::{Counter, Gauge};
use crate::core::{error::{Error, Result}, types::*};

// ===== Level 1: Core Buffer Types =====
// Design Choice: Using BytesMut for zero-copy

/// Buffer pool configuration
#[derive(Debug, Clone)]
pub struct BufferConfig {
    /// Initial buffer size
    pub initial_size: usize,
    /// Maximum buffer size
    pub max_size: usize,
    /// Pool capacity
    pub pool_capacity: usize,
}

// ===== Level 2: Buffer Implementation =====
// Design Choice: Using Arc for shared buffers

/// Buffer pool implementation
pub struct BufferPool {
    /// Available buffers
    buffers: Arc<Mutex<Vec<BytesMut>>>,
    /// Buffer semaphore
    semaphore: Arc<Semaphore>,
    /// Pool configuration
    config: BufferConfig,
    /// Pool metrics
    metrics: BufferMetrics,
}

impl BufferPool {
    /// Creates new buffer pool
    pub fn new(config: BufferConfig) -> Self {
        let buffers = Arc::new(Mutex::new(Vec::with_capacity(config.pool_capacity)));
        let semaphore = Arc::new(Semaphore::new(config.pool_capacity));
        let metrics = BufferMetrics::new();

        Self {
            buffers,
            semaphore,
            config,
            metrics,
        }
    }

    /// Acquires buffer from pool
    pub async fn acquire(&self) -> Result<BufferGuard> {
        let _permit = self.semaphore.acquire().await?;
        
        let mut buffers = self.buffers.lock().await;
        let buffer = buffers.pop()
            .unwrap_or_else(|| BytesMut::with_capacity(self.config.initial_size));

        self.metrics.active_buffers.increment(1.0);
        
        Ok(BufferGuard {
            buffer,
            pool: self.clone(),
        })
    }

    /// Returns buffer to pool
    async fn release(&self, mut buffer: BytesMut) {
        buffer.clear();
        
        if buffer.capacity() <= self.config.max_size {
            self.buffers.lock().await.push(buffer);
        }

        self.metrics.active_buffers.decrement(1.0);
    }
}

// ===== Level 3: Pool Management =====
// Design Choice: Using RAII for buffer management

/// Buffer guard for automatic return
pub struct BufferGuard {
    /// Managed buffer
    buffer: BytesMut,
    /// Owner pool
    pool: BufferPool,
}

impl Drop for BufferGuard {
    fn drop(&mut self) {
        let buffer = std::mem::replace(&mut self.buffer, BytesMut::new());
        let pool = self.pool.clone();
        
        tokio::spawn(async move {
            pool.release(buffer).await;
        });
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_buffer_pool() {
        let config = BufferConfig {
            initial_size: 1024,
            max_size: 8192,
            pool_capacity: 10,
        };

        let pool = BufferPool::new(config);
        
        // Test buffer acquisition
        let guard = pool.acquire().await.unwrap();
        assert_eq!(guard.buffer.capacity(), 1024);
        
        // Buffer should be returned to pool on drop
        drop(guard);
        
        // Allow time for async release
        tokio::time::sleep(tokio::time::Duration::from_millis(10)).await;
        
        assert_eq!(pool.metrics.active_buffers.get(), 0.0);
    }
}

-e 

=== /home/amuldotexe/Desktop/GitHub202410/parseltongue/phase01/src/utils/mod.rs ===
//! Utility Infrastructure
//! 
//! Pyramid Structure:
//! 
//! Level 4 (Top): Utility Coordination
//! - UtilityManager    (coordinates utilities)
//! - MetricsAggregator (aggregates utility metrics)
//! - ResourceTracker   (tracks resource usage)
//! 
//! Level 3: Resource Management
//! - BufferManager     (manages buffers)
//! - ResourceManager   (manages resources)
//! - CleanupManager    (manages cleanup)
//! 
//! Level 2: Utility Traits
//! - AsyncResource     (async resource trait)
//! - BufferPool       (buffer pool trait)
//! - Cleanup          (cleanup trait)
//! 
//! Level 1 (Base): Core Utility Types
//! - UtilityConfig    (utility configuration)
//! - ResourceMetrics  (resource metrics)
//! - UtilityError    (utility errors)

pub mod resource;
pub mod buffer;
pub mod cleanup;

// Re-export main types
pub use resource::ResourceManager;
pub use buffer::BufferPool;
pub use cleanup::CleanupGuard;
-e 

=== /home/amuldotexe/Desktop/GitHub202410/parseltongue/phase01/src/utils/cleanup.rs ===
//! Resource Cleanup Infrastructure
//! 
//! Pyramid Structure:
//! 
//! Level 4 (Top): Cleanup Coordination
//! - CleanupManager    (manages cleanup)
//! - CleanupMetrics    (tracks cleanup)
//! - CleanupScheduler  (schedules cleanup)
//! 
//! Level 3: Cleanup Management
//! - CleanupHandler    (handles cleanup)
//! - CleanupMonitor    (monitors cleanup)
//! - CleanupLogger     (logs cleanup)
//! 
//! Level 2: Cleanup Implementation
//! - Cleanup           (cleanup implementation)
//! - CleanupState      (cleanup lifecycle)
//! - CleanupMetrics    (cleanup stats)
//! 
//! Level 1 (Base): Core Cleanup Types
//! - CleanupConfig     (cleanup configuration)
//! - CleanupMetrics    (cleanup metrics)
//! - CleanupError      (cleanup errors)

use std::sync::Arc;
use tokio::sync::Mutex;
use futures::Future;
use metrics::{Counter, Gauge};
use crate::core::{error::{Error, Result}, types::*};

// ===== Level 1: Core Cleanup Types =====
// Design Choice: Using futures for async cleanup

/// Cleanup configuration
#[derive(Debug, Clone)]
pub struct CleanupConfig {
    /// Cleanup timeout
    pub timeout: std::time::Duration,
    /// Enable metrics
    pub metrics_enabled: bool,
}

// ===== Level 2: Cleanup Implementation =====
// Design Choice: Using RAII for cleanup

/// Cleanup guard implementation
pub struct CleanupGuard<T> {
    /// Managed resource
    resource: Option<T>,
    /// Cleanup function
    cleanup: Box<dyn FnOnce(T) -> Box<dyn Future<Output = ()> + Send + Unpin> + Send>,
    /// Guard metrics
    metrics: Arc<CleanupMetrics>,
}

impl<T> CleanupGuard<T> {
    /// Creates new cleanup guard
    pub fn new<F, Fut>(resource: T, cleanup: F) -> Self
    where
        F: FnOnce(T) -> Fut + Send + 'static,
        Fut: Future<Output = ()> + Send + Unpin + 'static,
    {
        Self {
            resource: Some(resource),
            cleanup: Box::new(move |r| Box::new(cleanup(r))),
            metrics: Arc::new(CleanupMetrics::new()),
        }
    }
}

impl<T> Drop for CleanupGuard<T> {
    fn drop(&mut self) {
        if let Some(resource) = self.resource.take() {
            let cleanup = (self.cleanup)(resource);
            let metrics = self.metrics.clone();
            
            tokio::spawn(async move {
                cleanup.await;
                metrics.cleanups_completed.increment(1);
            });
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::sync::atomic::{AtomicBool, Ordering};

    #[tokio::test]
    async fn test_cleanup_guard() {
        let cleaned = Arc::new(AtomicBool::new(false));
        let cleaned_clone = cleaned.clone();
        
        {
            let guard = CleanupGuard::new(42, move |_| {
                let cleaned = cleaned_clone.clone();
                async move {
                    cleaned.store(true, Ordering::SeqCst);
                }
            });
            
            assert!(!cleaned.load(Ordering::SeqCst));
        }
        
        // Allow time for async cleanup
        tokio::time::sleep(tokio::time::Duration::from_millis(10)).await;
        
        assert!(cleaned.load(Ordering::SeqCst));
    }
}

-e 

=== /home/amuldotexe/Desktop/GitHub202410/parseltongue/phase01/src/cli/metrics.rs ===
//! CLI Metrics Display
//! 
//! Pyramid Structure:
//! 
//! Level 4 (Top): Metrics Display
//! - MetricsManager    (manages metrics display)
//! - DisplayFormatter  (formats metrics)
//! - OutputManager     (manages output)
//! 
//! Level 3: Metric Types
//! - PerformanceMetrics (performance stats)
//! - ResourceMetrics    (resource usage)
//! - OperationMetrics   (operation stats)
//! 
//! Level 2: Display Implementation
//! - MetricsRenderer   (renders metrics)
//! - UpdateManager     (manages updates)
//! - FormatManager     (manages formatting)
//! 
//! Level 1 (Base): Core Metrics Types
//! - MetricsConfig    (metrics configuration)
//! - MetricsFormat    (format configuration)
//! - DisplayError     (display errors)

use std::sync::Arc;
use tokio::sync::RwLock;
use metrics::{Counter, Gauge, Histogram};
use colored::*;
use crate::core::error::Result;

// ===== Level 1: Core Metrics Types =====
// Design Choice: Using metrics crate for collection

/// Metrics display configuration
#[derive(Debug, Clone)]
pub struct MetricsConfig {
    /// Enable metrics display
    pub show_metrics: bool,
    /// Update interval
    pub update_interval: std::time::Duration,
    /// Output format
    pub format: MetricsFormat,
}

/// Metrics format options
#[derive(Debug, Clone, Copy)]
pub enum MetricsFormat {
    Plain,
    Colored,
    Json,
}

impl Default for MetricsFormat {
    fn default() -> Self {
        Self::Colored
    }
}

// ===== Level 2: Display Implementation =====
// Design Choice: Using colored output

/// Metrics display implementation
pub struct MetricsDisplay {
    /// Display configuration
    config: MetricsConfig,
    /// Performance metrics
    performance: Arc<RwLock<PerformanceMetrics>>,
    /// Resource metrics
    resources: Arc<RwLock<ResourceMetrics>>,
    /// Operation metrics
    operations: Arc<RwLock<OperationMetrics>>,
}

impl MetricsDisplay {
    /// Creates new metrics display
    pub fn new(format: MetricsFormat) -> Self {
        let config = MetricsConfig {
            show_metrics: true,
            update_interval: std::time::Duration::from_secs(1),
            format,
        };

        Self {
            config,
            performance: Arc::new(RwLock::new(PerformanceMetrics::new())),
            resources: Arc::new(RwLock::new(ResourceMetrics::new())),
            operations: Arc::new(RwLock::new(OperationMetrics::new())),
        }
    }

    /// Starts metrics display
    pub async fn start(&self) -> Result<()> {
        if !self.config.show_metrics {
            return Ok(());
        }

        self.clear_screen()?;
        self.draw_header()?;
        
        Ok(())
    }

    /// Stops metrics display
    pub async fn stop(&self) -> Result<()> {
        if !self.config.show_metrics {
            return Ok(());
        }

        self.draw_summary().await?;
        
        Ok(())
    }

    // ===== Level 3: Metric Types =====
    // Design Choice: Using separate metric groups

    /// Updates performance metrics
    pub async fn update_performance(&self, metrics: PerformanceMetrics) -> Result<()> {
        if !self.config.show_metrics {
            return Ok(());
        }

        let mut perf = self.performance.write().await;
        *perf = metrics;
        self.draw_performance(&perf)?;
        
        Ok(())
    }

    /// Updates resource metrics
    pub async fn update_resources(&self, metrics: ResourceMetrics) -> Result<()> {
        if !self.config.show_metrics {
            return Ok(());
        }

        let mut res = self.resources.write().await;
        *res = metrics;
        self.draw_resources(&res)?;
        
        Ok(())
    }

    // ===== Level 4: Display Formatting =====
    // Design Choice: Using terminal control sequences

    /// Clears the screen
    fn clear_screen(&self) -> Result<()> {
        print!("\x1B[2J\x1B[1;1H");
        Ok(())
    }

    /// Draws the header
    fn draw_header(&self) -> Result<()> {
        match self.config.format {
            MetricsFormat::Plain => println!("=== Performance Metrics ==="),
            MetricsFormat::Colored => println!("{}", "=== Performance Metrics ===".blue().bold()),
            MetricsFormat::Json => println!("{{\"type\": \"header\"}}"),
        }
        Ok(())
    }

    /// Draws performance metrics
    fn draw_performance(&self, metrics: &PerformanceMetrics) -> Result<()> {
        match self.config.format {
            MetricsFormat::Plain => {
                println!("Tasks: {}", metrics.tasks.get());
                println!("Throughput: {} MB/s", metrics.throughput.get());
            }
            MetricsFormat::Colored => {
                println!("{}: {}", "Tasks".green(), metrics.tasks.get());
                println!("{}: {} MB/s", "Throughput".green(), metrics.throughput.get());
            }
            MetricsFormat::Json => {
                println!("{{\"tasks\": {}, \"throughput\": {}}}", 
                    metrics.tasks.get(), metrics.throughput.get());
            }
        }
        Ok(())
    }

    /// Draws resource metrics
    fn draw_resources(&self, metrics: &ResourceMetrics) -> Result<()> {
        match self.config.format {
            MetricsFormat::Plain => {
                println!("Memory: {} MB", metrics.memory.get());
                println!("CPU: {}%", metrics.cpu.get());
            }
            MetricsFormat::Colored => {
                println!("{}: {} MB", "Memory".yellow(), metrics.memory.get());
                println!("{}: {}%", "CPU".yellow(), metrics.cpu.get());
            }
            MetricsFormat::Json => {
                println!("{{\"memory\": {}, \"cpu\": {}}}", 
                    metrics.memory.get(), metrics.cpu.get());
            }
        }
        Ok(())
    }

    /// Draws summary
    async fn draw_summary(&self) -> Result<()> {
        let perf = self.performance.read().await;
        let res = self.resources.read().await;
        
        match self.config.format {
            MetricsFormat::Plain => {
                println!("\n=== Summary ===");
                println!("Total tasks: {}", perf.tasks.get());
                println!("Peak memory: {} MB", res.memory.get());
            }
            MetricsFormat::Colored => {
                println!("\n{}", "=== Summary ===".blue().bold());
                println!("{}: {}", "Total tasks".green(), perf.tasks.get());
                println!("{}: {} MB", "Peak memory".yellow(), res.memory.get());
            }
            MetricsFormat::Json => {
                println!("{{\"summary\": {{\"tasks\": {}, \"peak_memory\": {}}}}}", 
                    perf.tasks.get(), res.memory.get());
            }
        }
        Ok(())
    }
}

/// Performance metrics collection
#[derive(Debug)]
struct PerformanceMetrics {
    tasks: Counter,
    throughput: Gauge,
    latency: Histogram,
}

impl PerformanceMetrics {
    fn new() -> Self {
        Self {
            tasks: Counter::new(),
            throughput: Gauge::new(),
            latency: Histogram::new(),
        }
    }
}

/// Resource metrics collection
#[derive(Debug)]
struct ResourceMetrics {
    memory: Gauge,
    cpu: Gauge,
    disk: Gauge,
}

impl ResourceMetrics {
    fn new() -> Self {
        Self {
            memory: Gauge::new(),
            cpu: Gauge::new(),
            disk: Gauge::new(),
        }
    }
}

/// Operation metrics collection
#[derive(Debug)]
struct OperationMetrics {
    operations: Counter,
    errors: Counter,
    duration: Histogram,
}

impl OperationMetrics {
    fn new() -> Self {
        Self {
            operations: Counter::new(),
            errors: Counter::new(),
            duration: Histogram::new(),
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_metrics_display() {
        let display = MetricsDisplay::new(MetricsFormat::Plain);
        
        assert!(display.start().await.is_ok());
        
        let perf = PerformanceMetrics::new();
        assert!(display.update_performance(perf).await.is_ok());
        
        let res = ResourceMetrics::new();
        assert!(display.update_resources(res).await.is_ok());
        
        assert!(display.stop().await.is_ok());
    }
}
-e 

=== /home/amuldotexe/Desktop/GitHub202410/parseltongue/phase01/src/cli/args.rs ===
//! CLI Argument Handling
//! 
//! Pyramid Structure:
//! 
//! Level 4 (Top): Argument Processing
//! - ArgumentProcessor (processes arguments)
//! - Validator         (validates arguments)
//! 
//! Level 3: Argument Types
//! - InputArgs        (input file arguments)
//! - OutputArgs       (output configuration)
//! 
//! Level 2: Argument Implementation
//! - ArgParser        (argument parsing)
//! - ArgValidator     (validation logic)
//! 
//! Level 1 (Base): Core Argument Types
//! - Args            (argument structure)
//! - ArgError        (argument errors)
//! - ValidationRule  (validation rules)

use std::path::{Path, PathBuf};
use clap::Parser;
use crate::core::{error::Result, types::*};

// ===== Level 1: Core Argument Types =====
// Design Choice: Using clap for argument parsing

/// Command line arguments
#[derive(Parser, Debug)]
#[clap(author, version, about)]
pub struct Args {
    /// Input ZIP file path
    #[clap(short = 'i', long = "input-zip", value_parser = validate_input_path)]
    pub input_path: PathBuf,

    /// Output directory path
    #[clap(short = 'o', long = "output-dir", value_parser = validate_output_path)]
    pub output_dir: PathBuf,

    /// Enable verbose output
    #[clap(short = 'v', long = "verbose")]
    pub verbose: bool,
}

// ===== Level 2: Argument Implementation =====
// Design Choice: Using validation functions

/// Validates input path
fn validate_input_path(path: impl AsRef<Path>) -> std::result::Result<PathBuf, String> {
    let path = path.as_ref();
    
    // Check if path exists
    if !path.exists() {
        return Err(format!("Input file does not exist: {}", path.display()));
    }

    // Check if it's a file
    if !path.is_file() {
        return Err(format!("Input path is not a file: {}", path.display()));
    }

    // Check file extension
    if let Some(ext) = path.extension() {
        if ext != "zip" {
            return Err(format!(
                "Input file must have .zip extension, got: {}",
                path.display()
            ));
        }
    } else {
        return Err(format!("Input file has no extension: {}", path.display()));
    }

    // Check if file is readable
    match std::fs::metadata(path) {
        Ok(meta) => {
            #[cfg(unix)]
            {
                use std::os::unix::fs::MetadataExt;
                let mode = meta.mode();
                if mode & 0o444 == 0 {
                    return Err(format!("Input file is not readable: {}", path.display()));
                }
            }
        }
        Err(e) => {
            return Err(format!(
                "Failed to read metadata for input file {}: {}",
                path.display(), e
            ));
        }
    }

    Ok(path.to_path_buf())
}

/// Validates output path
fn validate_output_path(path: impl AsRef<Path>) -> std::result::Result<PathBuf, String> {
    let path = path.as_ref();
    
    // If path exists, check if it's a directory
    if path.exists() {
        if !path.is_dir() {
            return Err(format!(
                "Output path exists but is not a directory: {}", 
                path.display()
            ));
        }

        // Check if directory is writable
        match std::fs::metadata(path) {
            Ok(meta) => {
                #[cfg(unix)]
                {
                    use std::os::unix::fs::MetadataExt;
                    let mode = meta.mode();
                    if mode & 0o222 == 0 {
                        return Err(format!(
                            "Output directory is not writable: {}", 
                            path.display()
                        ));
                    }
                }
            }
            Err(e) => {
                return Err(format!(
                    "Failed to read metadata for output directory {}: {}", 
                    path.display(), e
                ));
            }
        }
    } else {
        // Try to create the directory
        if let Err(e) = std::fs::create_dir_all(path) {
            return Err(format!(
                "Failed to create output directory {}: {}", 
                path.display(), e
            ));
        }
    }

    // Verify path is absolute
    if !path.is_absolute() {
        return Err(format!(
            "Output directory must be an absolute path: {}", 
            path.display()
        ));
    }

    Ok(path.to_path_buf())
}

impl Args {
    /// Ensures all paths are canonicalized
    pub fn canonicalize_paths(&mut self) -> Result<()> {
        self.input_path = self.input_path.canonicalize().map_err(|e| 
            Error::InvalidPath(format!(
                "Failed to canonicalize input path {}: {}", 
                self.input_path.display(), e
            ))
        )?;

        self.output_dir = self.output_dir.canonicalize().map_err(|e| 
            Error::InvalidPath(format!(
                "Failed to canonicalize output path {}: {}", 
                self.output_dir.display(), e
            ))
        )?;

        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::TempDir;
    use std::fs::File;

    #[test]
    fn test_input_path_validation() {
        let temp_dir = TempDir::new().unwrap();
        
        // Test non-existent file
        let bad_path = temp_dir.path().join("nonexistent.zip");
        assert!(validate_input_path(&bad_path).is_err());

        // Test wrong extension
        let wrong_ext = temp_dir.path().join("test.txt");
        File::create(&wrong_ext).unwrap();
        assert!(validate_input_path(&wrong_ext).is_err());

        // Test valid ZIP file
        let good_path = temp_dir.path().join("test.zip");
        File::create(&good_path).unwrap();
        assert!(validate_input_path(&good_path).is_ok());
    }

    #[test]
    fn test_output_path_validation() {
        let temp_dir = TempDir::new().unwrap();
        
        // Test file as output
        let file_path = temp_dir.path().join("file");
        File::create(&file_path).unwrap();
        assert!(validate_output_path(&file_path).is_err());

        // Test valid directory
        assert!(validate_output_path(temp_dir.path()).is_ok());

        // Test non-absolute path
        assert!(validate_output_path("relative/path").is_err());
    }

    #[test]
    fn test_path_canonicalization() {
        let temp_dir = TempDir::new().unwrap();
        let zip_path = temp_dir.path().join("test.zip");
        File::create(&zip_path).unwrap();

        let mut args = Args {
            input_path: zip_path,
            output_dir: temp_dir.path().to_path_buf(),
            verbose: false,
        };

        assert!(args.canonicalize_paths().is_ok());
        assert!(args.input_path.is_absolute());
        assert!(args.output_dir.is_absolute());
    }
}
-e 

=== /home/amuldotexe/Desktop/GitHub202410/parseltongue/phase01/src/cli/progress.rs ===
//! Progress Display Management
//! 
//! Pyramid Structure:
//! 
//! Level 4 (Top): Progress Coordination
//! - ProgressManager   (manages progress display)
//! - ProgressMetrics   (tracks progress stats)
//! - DisplayManager    (manages output)
//! 
//! Level 3: Progress Types
//! - ProgressBar      (progress bar display)
//! - SpinnerDisplay   (activity spinner)
//! - StatusLine       (status messages)
//! 
//! Level 2: Display Implementation
//! - ProgressRenderer  (renders progress)
//! - StyleManager     (manages styles)
//! - UpdateManager    (manages updates)
//! 
//! Level 1 (Base): Core Progress Types
//! - ProgressConfig   (progress configuration)
//! - ProgressStyle    (style configuration)
//! - DisplayError     (display errors)

use std::sync::Arc;
use tokio::sync::RwLock;
use indicatif::{ProgressBar as IndicatifBar, ProgressStyle};
use metrics::{Counter, Gauge, Histogram};
use crate::core::error::Result;

// ===== Level 1: Core Progress Types =====
// Design Choice: Using indicatif for progress display

/// Progress display configuration
#[derive(Debug, Clone)]
pub struct ProgressConfig {
    /// Enable progress bar
    pub show_progress: bool,
    /// Update interval
    pub update_interval: std::time::Duration,
    /// Progress style
    pub style: ProgressStyle,
}

impl Default for ProgressConfig {
    fn default() -> Self {
        Self {
            show_progress: true,
            update_interval: std::time::Duration::from_millis(100),
            style: ProgressStyle::default_bar()
                .template("[{elapsed_precise}] {bar:40.cyan/blue} {pos:>7}/{len:7} {msg}")
                .unwrap()
                .progress_chars("##-"),
        }
    }
}

// ===== Level 2: Display Implementation =====
// Design Choice: Using async updates

/// Progress bar implementation
pub struct ProgressBar {
    /// Inner progress bar
    bar: Arc<IndicatifBar>,
    /// Progress configuration
    config: ProgressConfig,
    /// Progress metrics
    metrics: ProgressMetrics,
    /// Current state
    state: Arc<RwLock<ProgressState>>,
}

impl ProgressBar {
    /// Creates new progress bar
    pub fn new() -> Self {
        Self::new_with_style(ProgressStyle::default_bar())
    }

    /// Creates new progress bar with style
    pub fn new_with_style(style: ProgressStyle) -> Self {
        let config = ProgressConfig {
            style,
            ..Default::default()
        };

        let bar = IndicatifBar::new(100);
        bar.set_style(config.style.clone());

        Self {
            bar: Arc::new(bar),
            config,
            metrics: ProgressMetrics::new(),
            state: Arc::new(RwLock::new(ProgressState::new())),
        }
    }

    /// Sets progress length
    pub fn set_length(&self, len: u64) {
        self.bar.set_length(len);
    }

    /// Sets progress position
    pub async fn set_position(&self, pos: u64) -> Result<()> {
        let mut state = self.state.write().await;
        state.position = pos;
        
        if self.config.show_progress {
            self.bar.set_position(pos);
            self.metrics.updates.increment(1);
        }
        
        Ok(())
    }

    /// Sets progress message
    pub fn set_message<S: Into<String>>(&self, msg: S) {
        if self.config.show_progress {
            self.bar.set_message(msg);
        }
    }

    /// Finishes progress bar
    pub fn finish_with_message<S: Into<String>>(&self, msg: S) {
        if self.config.show_progress {
            self.bar.finish_with_message(msg);
        }
    }
}

// ===== Level 3: Progress Types =====
// Design Choice: Using separate types for different displays

/// Progress state tracking
#[derive(Debug)]
struct ProgressState {
    position: u64,
    total: u64,
    message: String,
}

impl ProgressState {
    fn new() -> Self {
        Self {
            position: 0,
            total: 100,
            message: String::new(),
        }
    }
}

/// Progress metrics collection
#[derive(Debug)]
struct ProgressMetrics {
    updates: Counter,
    refresh_rate: Histogram,
    active_bars: Gauge,
}

impl ProgressMetrics {
    fn new() -> Self {
        Self {
            updates: Counter::new(),
            refresh_rate: Histogram::new(),
            active_bars: Gauge::new(),
        }
    }
}

// ===== Level 4: Progress Coordination =====
// Design Choice: Using multi-progress for multiple bars

/// Progress manager implementation
pub struct ProgressManager {
    /// Active progress bars
    bars: Arc<RwLock<Vec<Arc<ProgressBar>>>>,
    /// Manager configuration
    config: ProgressConfig,
    /// Manager metrics
    metrics: ProgressMetrics,
}

impl ProgressManager {
    /// Creates new progress manager
    pub fn new(config: ProgressConfig) -> Self {
        Self {
            bars: Arc::new(RwLock::new(Vec::new())),
            config,
            metrics: ProgressMetrics::new(),
        }
    }

    /// Creates new progress bar
    pub async fn create_bar(&self) -> Arc<ProgressBar> {
        let bar = Arc::new(ProgressBar::new_with_style(self.config.style.clone()));
        self.bars.write().await.push(bar.clone());
        self.metrics.active_bars.increment(1.0);
        bar
    }

    /// Updates all progress bars
    pub async fn update_all(&self) -> Result<()> {
        let bars = self.bars.read().await;
        for bar in bars.iter() {
            let state = bar.state.read().await;
            bar.set_position(state.position).await?;
        }
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_progress_bar() {
        let bar = ProgressBar::new();
        
        bar.set_length(100);
        assert!(bar.set_position(50).await.is_ok());
        
        bar.set_message("Testing...");
        bar.finish_with_message("Done!");
    }

    #[tokio::test]
    async fn test_progress_manager() {
        let config = ProgressConfig::default();
        let manager = ProgressManager::new(config);
        
        let bar = manager.create_bar().await;
        assert!(bar.set_position(50).await.is_ok());
        
        assert!(manager.update_all().await.is_ok());
    }
}
-e 

=== /home/amuldotexe/Desktop/GitHub202410/parseltongue/phase01/src/cli/mod.rs ===
//! CLI Layer Coordination
//! 
//! Pyramid Structure:
//! 
//! Level 4 (Top): CLI Orchestration
//! - CliManager       (coordinates all CLI components)
//! - CliMetrics       (aggregates CLI performance)
//! - UserInterface    (manages user interaction)
//! 
//! Level 3: Feature Management
//! - ArgumentManager  (manages CLI arguments)
//! - ProgressManager  (manages progress display)
//! - MetricsManager   (manages metrics display)
//! 
//! Level 2: CLI Traits
//! - CliCommand       (command interface)
//! - ProgressDisplay  (progress interface)
//! - MetricsDisplay   (metrics interface)
//! 
//! Level 1 (Base): Core CLI Types
//! - CliConfig       (CLI configuration)
//! - CliError        (CLI-specific errors)
//! - DisplayConfig   (display settings)

pub mod args;
pub mod progress;
pub mod metrics;

use std::sync::Arc;
use tokio::sync::RwLock;
use crate::core::error::Result;

// Re-export main types
pub use args::Args;
pub use progress::ProgressBar;
pub use metrics::MetricsDisplay;

// ===== Level 1: Core CLI Types =====
// Design Choice: Using builder pattern for configuration

/// CLI configuration
#[derive(Debug, Clone)]
pub struct CliConfig {
    /// Enable verbose output
    pub verbose: bool,
    /// Progress bar style
    pub progress_style: ProgressStyle,
    /// Metrics display format
    pub metrics_format: MetricsFormat,
}

/// CLI error types
#[derive(Debug, thiserror::Error)]
pub enum CliError {
    #[error("Invalid argument: {0}")]
    InvalidArgument(String),
    #[error("Display error: {0}")]
    DisplayError(String),
    #[error("Progress error: {0}")]
    ProgressError(String),
}

// ===== Level 2: CLI Traits =====
// Design Choice: Using async traits for operations

/// CLI command interface
#[async_trait::async_trait]
pub trait CliCommand {
    /// Execute command
    async fn execute(&self) -> Result<()>;
    /// Display progress
    async fn display_progress(&self) -> Result<()>;
    /// Show metrics
    async fn show_metrics(&self) -> Result<()>;
}

/// Progress display interface
#[async_trait::async_trait]
pub trait ProgressDisplay: Send + Sync {
    /// Update progress
    async fn update(&self, current: u64, total: u64) -> Result<()>;
    /// Set message
    async fn set_message(&self, msg: &str) -> Result<()>;
    /// Finish progress
    async fn finish(&self) -> Result<()>;
}

// ===== Level 3: Feature Management =====
// Design Choice: Using separate managers for features

/// CLI manager implementation
pub struct CliManager {
    /// CLI configuration
    config: CliConfig,
    /// Argument manager
    args: Arc<ArgumentManager>,
    /// Progress manager
    progress: Arc<ProgressManager>,
    /// Metrics manager
    metrics: Arc<MetricsManager>,
}

impl CliManager {
    /// Creates new CLI manager
    pub fn new(config: CliConfig) -> Self {
        let args = Arc::new(ArgumentManager::new());
        let progress = Arc::new(ProgressManager::new(config.progress_style.clone()));
        let metrics = Arc::new(MetricsManager::new(config.metrics_format.clone()));

        Self {
            config,
            args,
            progress,
            metrics,
        }
    }

    /// Executes CLI command
    pub async fn execute<C: CliCommand>(&self, command: C) -> Result<()> {
        // Start metrics collection
        self.metrics.start().await?;

        // Execute command with progress
        let progress = self.progress.create_progress_bar();
        command.execute().await?;
        progress.finish().await?;

        // Stop metrics collection
        self.metrics.stop().await?;

        Ok(())
    }
}

// ===== Level 4: CLI Orchestration =====
// Design Choice: Using separate components for modularity

/// Argument manager implementation
struct ArgumentManager {
    /// Parsed arguments
    args: RwLock<Option<Args>>,
}

impl ArgumentManager {
    fn new() -> Self {
        Self {
            args: RwLock::new(None),
        }
    }

    async fn parse_args(&self) -> Result<Args> {
        use clap::Parser;
        Ok(Args::parse())
    }
}

/// Progress manager implementation
struct ProgressManager {
    /// Progress style
    style: ProgressStyle,
    /// Active progress bars
    progress_bars: RwLock<Vec<Arc<dyn ProgressDisplay>>>,
}

impl ProgressManager {
    fn new(style: ProgressStyle) -> Self {
        Self {
            style,
            progress_bars: RwLock::new(Vec::new()),
        }
    }

    async fn create_progress_bar(&self) -> Arc<dyn ProgressDisplay> {
        let bar = Arc::new(ProgressBar::new_with_style(self.style.clone()));
        self.progress_bars.write().await.push(bar.clone());
        bar
    }
}

/// Metrics manager implementation
struct MetricsManager {
    /// Metrics format
    format: MetricsFormat,
    /// Metrics display
    display: Arc<MetricsDisplay>,
}

impl MetricsManager {
    fn new(format: MetricsFormat) -> Self {
        Self {
            format,
            display: Arc::new(MetricsDisplay::new(format)),
        }
    }

    async fn start(&self) -> Result<()> {
        self.display.start().await
    }

    async fn stop(&self) -> Result<()> {
        self.display.stop().await
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_cli_manager() {
        let config = CliConfig {
            verbose: true,
            progress_style: ProgressStyle::default(),
            metrics_format: MetricsFormat::default(),
        };

        let manager = CliManager::new(config);
        
        struct TestCommand;
        
        #[async_trait::async_trait]
        impl CliCommand for TestCommand {
            async fn execute(&self) -> Result<()> {
                Ok(())
            }
            
            async fn display_progress(&self) -> Result<()> {
                Ok(())
            }
            
            async fn show_metrics(&self) -> Result<()> {
                Ok(())
            }
        }

        assert!(manager.execute(TestCommand).await.is_ok());
    }
}
-e 

